{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89a8a9d0-2e2d-4db7-bf44-e8538a71ca0e",
   "metadata": {},
   "source": [
    "\n",
    "## Diffusion Model\n",
    "\n",
    "* So let's start by importing all required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86ebe887-bd3a-4956-a89c-631499242869",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60a8bae-5f4c-49da-8c26-215553ccf63d",
   "metadata": {},
   "source": [
    "<hr style=\"border: 1px solid black;\">\n",
    "\n",
    "* Let's first read shakespeare data and see unique characters in it so that we can remove unwanted characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6204c4a-469a-43a9-a83a-83479583991a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'3', 'l', '\"', '?', 'V', 'u', 'y', 'I', 'k', 'U', '!', 'f', 'T', 't', 'S', 'J', 'W', 'v', '.', '7', '1', 'z', 'O', 'r', 'm', 'R', 'b', 'q', 'i', '9', 'E', 'w', ' ', '4', ',', '-', '\\n', '6', 'g', 'H', 'j', 'a', '0', 'p', ';', 'M', ']', 'h', 'L', 'K', 'n', 'F', ':', 'B', 'c', 'Y', 'A', '8', 'P', '[', 's', 'C', '5', 'x', 'G', 'D', 'd', \"'\", '2', 'N', 'o', 'e'}\n"
     ]
    }
   ],
   "source": [
    "with open(\"./data/shakespeare-sonnets.txt\", \"r\") as f:\n",
    "    print(set(f.read()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035daf0f-9f03-4673-9883-b2615c4da5ba",
   "metadata": {},
   "source": [
    "* As you can see from above that there are characters like square brackets and numbers which we dont want\n",
    "* So let's start by first writing a function for cleaning text\n",
    "* In this function we are going to remove "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6ec84e5-3aa3-4aaa-b416-b7b3e707cae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_shakespeare_text(text):\n",
    "    \"\"\"Function to clean given text\"\"\"\n",
    "    # Removing numbers\n",
    "    pattern = r'\\d+'\n",
    "    text = re.sub(pattern, \"\", text)\n",
    "    # Removing square brackets\n",
    "    text = re.sub(r'\\[\\]', '', text, flags=re.MULTILINE)\n",
    "    # Splitting lines by next line character\n",
    "    lines = text.split('\\n')\n",
    "    cleaned_lines = []\n",
    "    for line in lines:\n",
    "        # Removing spaces from start and end of line\n",
    "        stripped_line = line.strip()\n",
    "        # Skipping empty line\n",
    "        if not stripped_line:\n",
    "            continue\n",
    "        cleaned_lines.append(stripped_line)\n",
    "    return cleaned_lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788d3c79-3b5c-4941-a6ef-0941e3c4de53",
   "metadata": {},
   "source": [
    "* Now let's test this function and see if it's working or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6b6053a-d86b-4fe6-bb1b-a39822aae705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abcdefg', 'abc?']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_shakespeare_text(\"1\\n abcdefg \\n        1256           \\nabc?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486af3c6-9b8f-426d-ba19-7bb50922f45f",
   "metadata": {},
   "source": [
    "* As you can see that the function is working as expected\n",
    "* Now let's get our cleaned shakespeare text data by passing it through this function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d472584-49f4-4bb5-b74c-9eda5b831287",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data = []\n",
    "with open(\"./data/shakespeare-sonnets.txt\", \"r\") as f:\n",
    "    cleaned_data = clean_shakespeare_text(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b572b3-53c4-46d3-871c-83efd152eb4f",
   "metadata": {},
   "source": [
    "* Now let's see first 10 lines of cleaned data and also see it's length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34c516e6-ffc7-4fa3-8024-2c9fa065ca80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2183,\n",
       " ['From fairest creatures we desire increase,',\n",
       "  \"That thereby beauty's rose might never die,\",\n",
       "  'But, as the riper should by time decease,',\n",
       "  'His tender heir might bear his memory.',\n",
       "  'But thou, contracted to thine own bright eyes,',\n",
       "  \"Feed'st thy light's flame with self-substantial fuel,\",\n",
       "  'Making a famine where abundance lies,',\n",
       "  'Thyself thy foe, to thy sweet self too cruel.',\n",
       "  \"Thou that art now the world's fresh ornament\",\n",
       "  'And only herald to the gaudy spring'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cleaned_data), cleaned_data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2e1b3c-6c80-4368-a1ab-bbe492062a0c",
   "metadata": {},
   "source": [
    "* Now let's write a function to prepare samples of shakespeare text\n",
    "* This function will have four parameters which says whether to include single line, two lines (couplets), four lines (quatrain) and fourteen lines (sonnet) and return samples accordingly\n",
    "* So we are using different samples because :\n",
    "    - Single line - learn vocabulary\n",
    "    - Two lines (couplet) - learn how two lines connect\n",
    "    - Four lines (quatrain) - learn rhyme patterns in line\n",
    "    - Fourteen lines (sonnet) - learn poem structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4f1c5e9-1dc7-4cbc-b22d-07af13c5be71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_mixed_samples(lines, include_single=True, include_couplet=True, include_quatrain=True, include_sonnet=True):\n",
    "    \"\"\"Function to return requested length samples\"\"\"\n",
    "    all_samples = []\n",
    "    # If single is true then include single line in all_samples\n",
    "    if include_single:\n",
    "        for line in lines:\n",
    "            all_samples.append({'text': line, 'type': 'single', 'num_lines': 1})\n",
    "    # If couplet is true then include two lines in all_samples\n",
    "    if include_couplet:\n",
    "        for i in range(0, len(lines) - 1, 2):\n",
    "            couplet = f\"{lines[i]}\\n{lines[i+1]}\"\n",
    "            all_samples.append({'text': couplet, 'type': 'couplet', 'num_lines': 2})\n",
    "    # If quatrain is true then include four lines in all_samples\n",
    "    if include_quatrain:\n",
    "        for i in range(0, len(lines) - 3, 4):\n",
    "            quatrain = '\\n'.join(lines[i:i+4])\n",
    "            all_samples.append({'text': quatrain, 'type': 'quatrain', 'num_lines': 4})\n",
    "    # If sonnet is true then include fourteen lines in all_samples\n",
    "    if include_sonnet:\n",
    "        for i in range(0, len(lines) - 13, 14):\n",
    "            sonnet = '\\n'.join(lines[i:i+14])\n",
    "            all_samples.append({'text': sonnet, 'type': 'sonnet', 'num_lines': 14})\n",
    "    return all_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9ced1c-9f6e-47ce-bc0e-b5a101d97c90",
   "metadata": {},
   "source": [
    "* Now let's test this function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f6cd1b6-202d-45d1-ab64-eaf8e1cd712b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'abcd', 'type': 'single', 'num_lines': 1},\n",
       " {'text': 'abcd', 'type': 'single', 'num_lines': 1},\n",
       " {'text': 'abcd', 'type': 'single', 'num_lines': 1},\n",
       " {'text': 'abcd', 'type': 'single', 'num_lines': 1},\n",
       " {'text': 'abcd', 'type': 'single', 'num_lines': 1},\n",
       " {'text': 'abcd', 'type': 'single', 'num_lines': 1},\n",
       " {'text': 'abcd', 'type': 'single', 'num_lines': 1},\n",
       " {'text': 'abcd', 'type': 'single', 'num_lines': 1},\n",
       " {'text': 'abcd', 'type': 'single', 'num_lines': 1},\n",
       " {'text': 'abcd', 'type': 'single', 'num_lines': 1},\n",
       " {'text': 'abcd', 'type': 'single', 'num_lines': 1},\n",
       " {'text': 'abcd', 'type': 'single', 'num_lines': 1},\n",
       " {'text': 'abcd', 'type': 'single', 'num_lines': 1},\n",
       " {'text': 'abcd', 'type': 'single', 'num_lines': 1},\n",
       " {'text': 'abcd', 'type': 'single', 'num_lines': 1},\n",
       " {'text': 'abcd', 'type': 'single', 'num_lines': 1},\n",
       " {'text': 'abcd', 'type': 'single', 'num_lines': 1},\n",
       " {'text': 'abcd', 'type': 'single', 'num_lines': 1},\n",
       " {'text': 'abcd', 'type': 'single', 'num_lines': 1},\n",
       " {'text': 'abcd', 'type': 'single', 'num_lines': 1}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = [\"abcd\" for _ in range(20)]\n",
    "prepare_mixed_samples(test_data, include_single=True, include_couplet=False, include_quatrain=False, include_sonnet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f9075b3-9ad0-456f-835a-787e15bed720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'abcd', 'type': 'single', 'num_lines': 1},\n",
       " {'text': 'abcd', 'type': 'single', 'num_lines': 1},\n",
       " {'text': 'abcd', 'type': 'single', 'num_lines': 1},\n",
       " {'text': 'abcd', 'type': 'single', 'num_lines': 1},\n",
       " {'text': 'abcd', 'type': 'single', 'num_lines': 1},\n",
       " {'text': 'abcd', 'type': 'single', 'num_lines': 1},\n",
       " {'text': 'abcd', 'type': 'single', 'num_lines': 1},\n",
       " {'text': 'abcd', 'type': 'single', 'num_lines': 1},\n",
       " {'text': 'abcd', 'type': 'single', 'num_lines': 1},\n",
       " {'text': 'abcd', 'type': 'single', 'num_lines': 1},\n",
       " {'text': 'abcd', 'type': 'single', 'num_lines': 1},\n",
       " {'text': 'abcd', 'type': 'single', 'num_lines': 1},\n",
       " {'text': 'abcd', 'type': 'single', 'num_lines': 1},\n",
       " {'text': 'abcd', 'type': 'single', 'num_lines': 1},\n",
       " {'text': 'abcd', 'type': 'single', 'num_lines': 1},\n",
       " {'text': 'abcd', 'type': 'single', 'num_lines': 1},\n",
       " {'text': 'abcd', 'type': 'single', 'num_lines': 1},\n",
       " {'text': 'abcd', 'type': 'single', 'num_lines': 1},\n",
       " {'text': 'abcd', 'type': 'single', 'num_lines': 1},\n",
       " {'text': 'abcd', 'type': 'single', 'num_lines': 1},\n",
       " {'text': 'abcd\\nabcd', 'type': 'couplet', 'num_lines': 2},\n",
       " {'text': 'abcd\\nabcd', 'type': 'couplet', 'num_lines': 2},\n",
       " {'text': 'abcd\\nabcd', 'type': 'couplet', 'num_lines': 2},\n",
       " {'text': 'abcd\\nabcd', 'type': 'couplet', 'num_lines': 2},\n",
       " {'text': 'abcd\\nabcd', 'type': 'couplet', 'num_lines': 2},\n",
       " {'text': 'abcd\\nabcd', 'type': 'couplet', 'num_lines': 2},\n",
       " {'text': 'abcd\\nabcd', 'type': 'couplet', 'num_lines': 2},\n",
       " {'text': 'abcd\\nabcd', 'type': 'couplet', 'num_lines': 2},\n",
       " {'text': 'abcd\\nabcd', 'type': 'couplet', 'num_lines': 2},\n",
       " {'text': 'abcd\\nabcd', 'type': 'couplet', 'num_lines': 2}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepare_mixed_samples(test_data, include_single=True, include_couplet=True, include_quatrain=False, include_sonnet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69820162-a5b6-465f-a8f3-0e10783e7c5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'abcd', 'type': 'single', 'num_lines': 1},\n",
       " {'text': 'abcd', 'type': 'single', 'num_lines': 1},\n",
       " {'text': 'abcd', 'type': 'single', 'num_lines': 1},\n",
       " {'text': 'abcd', 'type': 'single', 'num_lines': 1},\n",
       " {'text': 'abcd', 'type': 'single', 'num_lines': 1},\n",
       " {'text': 'abcd', 'type': 'single', 'num_lines': 1},\n",
       " {'text': 'abcd', 'type': 'single', 'num_lines': 1},\n",
       " {'text': 'abcd', 'type': 'single', 'num_lines': 1},\n",
       " {'text': 'abcd', 'type': 'single', 'num_lines': 1},\n",
       " {'text': 'abcd', 'type': 'single', 'num_lines': 1},\n",
       " {'text': 'abcd', 'type': 'single', 'num_lines': 1},\n",
       " {'text': 'abcd', 'type': 'single', 'num_lines': 1},\n",
       " {'text': 'abcd', 'type': 'single', 'num_lines': 1},\n",
       " {'text': 'abcd', 'type': 'single', 'num_lines': 1},\n",
       " {'text': 'abcd', 'type': 'single', 'num_lines': 1},\n",
       " {'text': 'abcd', 'type': 'single', 'num_lines': 1},\n",
       " {'text': 'abcd', 'type': 'single', 'num_lines': 1},\n",
       " {'text': 'abcd', 'type': 'single', 'num_lines': 1},\n",
       " {'text': 'abcd', 'type': 'single', 'num_lines': 1},\n",
       " {'text': 'abcd', 'type': 'single', 'num_lines': 1},\n",
       " {'text': 'abcd\\nabcd', 'type': 'couplet', 'num_lines': 2},\n",
       " {'text': 'abcd\\nabcd', 'type': 'couplet', 'num_lines': 2},\n",
       " {'text': 'abcd\\nabcd', 'type': 'couplet', 'num_lines': 2},\n",
       " {'text': 'abcd\\nabcd', 'type': 'couplet', 'num_lines': 2},\n",
       " {'text': 'abcd\\nabcd', 'type': 'couplet', 'num_lines': 2},\n",
       " {'text': 'abcd\\nabcd', 'type': 'couplet', 'num_lines': 2},\n",
       " {'text': 'abcd\\nabcd', 'type': 'couplet', 'num_lines': 2},\n",
       " {'text': 'abcd\\nabcd', 'type': 'couplet', 'num_lines': 2},\n",
       " {'text': 'abcd\\nabcd', 'type': 'couplet', 'num_lines': 2},\n",
       " {'text': 'abcd\\nabcd', 'type': 'couplet', 'num_lines': 2},\n",
       " {'text': 'abcd\\nabcd\\nabcd\\nabcd', 'type': 'quatrain', 'num_lines': 4},\n",
       " {'text': 'abcd\\nabcd\\nabcd\\nabcd', 'type': 'quatrain', 'num_lines': 4},\n",
       " {'text': 'abcd\\nabcd\\nabcd\\nabcd', 'type': 'quatrain', 'num_lines': 4},\n",
       " {'text': 'abcd\\nabcd\\nabcd\\nabcd', 'type': 'quatrain', 'num_lines': 4},\n",
       " {'text': 'abcd\\nabcd\\nabcd\\nabcd', 'type': 'quatrain', 'num_lines': 4}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepare_mixed_samples(test_data, include_single=True, include_couplet=True, include_quatrain=True, include_sonnet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0588ac27-3f1d-4211-811b-aee9172d25a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'abcd', 'type': 'single', 'num_lines': 1},\n",
       " {'text': 'abcd', 'type': 'single', 'num_lines': 1},\n",
       " {'text': 'abcd', 'type': 'single', 'num_lines': 1},\n",
       " {'text': 'abcd', 'type': 'single', 'num_lines': 1},\n",
       " {'text': 'abcd', 'type': 'single', 'num_lines': 1},\n",
       " {'text': 'abcd', 'type': 'single', 'num_lines': 1},\n",
       " {'text': 'abcd', 'type': 'single', 'num_lines': 1},\n",
       " {'text': 'abcd', 'type': 'single', 'num_lines': 1},\n",
       " {'text': 'abcd', 'type': 'single', 'num_lines': 1},\n",
       " {'text': 'abcd', 'type': 'single', 'num_lines': 1},\n",
       " {'text': 'abcd', 'type': 'single', 'num_lines': 1},\n",
       " {'text': 'abcd', 'type': 'single', 'num_lines': 1},\n",
       " {'text': 'abcd', 'type': 'single', 'num_lines': 1},\n",
       " {'text': 'abcd', 'type': 'single', 'num_lines': 1},\n",
       " {'text': 'abcd', 'type': 'single', 'num_lines': 1},\n",
       " {'text': 'abcd', 'type': 'single', 'num_lines': 1},\n",
       " {'text': 'abcd', 'type': 'single', 'num_lines': 1},\n",
       " {'text': 'abcd', 'type': 'single', 'num_lines': 1},\n",
       " {'text': 'abcd', 'type': 'single', 'num_lines': 1},\n",
       " {'text': 'abcd', 'type': 'single', 'num_lines': 1},\n",
       " {'text': 'abcd\\nabcd', 'type': 'couplet', 'num_lines': 2},\n",
       " {'text': 'abcd\\nabcd', 'type': 'couplet', 'num_lines': 2},\n",
       " {'text': 'abcd\\nabcd', 'type': 'couplet', 'num_lines': 2},\n",
       " {'text': 'abcd\\nabcd', 'type': 'couplet', 'num_lines': 2},\n",
       " {'text': 'abcd\\nabcd', 'type': 'couplet', 'num_lines': 2},\n",
       " {'text': 'abcd\\nabcd', 'type': 'couplet', 'num_lines': 2},\n",
       " {'text': 'abcd\\nabcd', 'type': 'couplet', 'num_lines': 2},\n",
       " {'text': 'abcd\\nabcd', 'type': 'couplet', 'num_lines': 2},\n",
       " {'text': 'abcd\\nabcd', 'type': 'couplet', 'num_lines': 2},\n",
       " {'text': 'abcd\\nabcd', 'type': 'couplet', 'num_lines': 2},\n",
       " {'text': 'abcd\\nabcd\\nabcd\\nabcd', 'type': 'quatrain', 'num_lines': 4},\n",
       " {'text': 'abcd\\nabcd\\nabcd\\nabcd', 'type': 'quatrain', 'num_lines': 4},\n",
       " {'text': 'abcd\\nabcd\\nabcd\\nabcd', 'type': 'quatrain', 'num_lines': 4},\n",
       " {'text': 'abcd\\nabcd\\nabcd\\nabcd', 'type': 'quatrain', 'num_lines': 4},\n",
       " {'text': 'abcd\\nabcd\\nabcd\\nabcd', 'type': 'quatrain', 'num_lines': 4},\n",
       " {'text': 'abcd\\nabcd\\nabcd\\nabcd\\nabcd\\nabcd\\nabcd\\nabcd\\nabcd\\nabcd\\nabcd\\nabcd\\nabcd\\nabcd',\n",
       "  'type': 'sonnet',\n",
       "  'num_lines': 14}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepare_mixed_samples(test_data, include_single=True, include_couplet=True, include_quatrain=True, include_sonnet=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c68a16f-7a65-496a-8047-23e8d310442a",
   "metadata": {},
   "source": [
    "* As you can see from above that the function is working as expected\n",
    "* So let's pass cleaned shakespeare data to this function and get all samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "768b0e10-2b0d-4804-b282-99f0c3d8436e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'From fairest creatures we desire increase,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"That thereby beauty's rose might never die,\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'But, as the riper should by time decease,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'His tender heir might bear his memory.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'But thou, contracted to thine own bright eyes,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"Feed'st thy light's flame with self-substantial fuel,\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Making a famine where abundance lies,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Thyself thy foe, to thy sweet self too cruel.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"Thou that art now the world's fresh ornament\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And only herald to the gaudy spring',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Within thine own bud buriest thy content',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"And, tender churl, mak'st waste in niggarding.\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Pity the world, or else this glutton be--',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"To eat the world's due, by the grave and thee.\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'When forty winters shall besiege thy brow',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"And dig deep trenches in thy beauty's field,\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"Thy youth's proud livery, so gazed on now,\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Will be a tattered weed of small worth held.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Then being asked where all thy beauty lies,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Where all the treasure of thy lusty days,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'To say within thine own deep-sunken eyes',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Were an all-eating shame and thriftless praise.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"How much more praise deserved thy beauty's use\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'If thou couldst answer \"This fair child of mine',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Shall sum my count and make my old excuse,\"',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Proving his beauty by succession thine.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'This were to be new made when thou art old',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"And see thy blood warm when thou feel'st it cold.\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Look in thy glass and tell the face thou viewest',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Now is the time that face should form another,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Whose fresh repair if now thou not renewest,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Thou dost beguile the world, unbless some mother.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'For where is she so fair whose uneared womb',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Disdains the tillage of thy husbandry?',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Or who is he so fond will be the tomb',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Of his self-love, to stop posterity?',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"Thou art thy mother's glass, and she in thee\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Calls back the lovely April of her prime;',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'So thou through windows of thine age shalt see,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Despite of wrinkles, this thy golden time.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'But if thou live remembered not to be,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Die single, and thine image dies with thee.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Unthrifty loveliness, why dost thou spend',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"Upon thyself thy beauty's legacy?\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"Nature's bequest gives nothing but doth lend,\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And being frank, she lends to those are free.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Then, beauteous niggard, why dost thou abuse',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'The bounteous largess given thee to give?',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Profitless usurer, why dost thou use',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'So great a sum of sums yet canst not live?',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'For, having traffic with thyself alone,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Thou of thyself thy sweet self dost deceive.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Then how, when nature calls thee to be gone,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'What acceptable audit canst thou leave?',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Thy unused beauty must be tombed with thee,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"Which used lives th' executor to be.\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Those hours that with gentle work did frame',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'The lovely gaze where every eye doth dwell',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Will play the tyrants to the very same',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And that unfair which fairly doth excel;',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'For never-resting time leads summer on',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'To hideous winter and confounds him there,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Sap checked with frost and lusty leaves quite gone,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"Beauty o'er-snowed and bareness everywhere.\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"Then, were not summer's distillation left\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'A liquid prisoner pent in walls of glass,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"Beauty's effect with beauty were bereft,\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Nor it nor no remembrance what it was.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'But flowers distilled, though they with winter meet,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Leese but their show; their substance still lives sweet.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"Then let not winter's ragged hand deface\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'In thee thy summer ere thou be distilled.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Make sweet some vial; treasure thou some place',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"With beauty's treasure ere it be self-killed.\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'That use is not forbidden usury', 'type': 'single', 'num_lines': 1},\n",
       " {'text': 'Which happies those that pay the willing loan;',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"That's for thyself to breed another thee,\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Or ten times happier, be it ten for one.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Ten times thyself were happier than thou art',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'If ten of thine ten times refigured thee;',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Then what could death do if thou shouldst depart,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Leaving thee living in posterity?',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Be not self-willed, for thou art much too fair',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"To be death's conquest and make worms thine heir.\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Lo, in the orient when the gracious light',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Lifts up his burning head, each under eye',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Doth homage to his new-appearing sight,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Serving with looks his sacred majesty;',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And having climbed the steep-up heavenly hill,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Resembling strong youth in his middle age,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Yet mortal looks adore his beauty still,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Attending on his golden pilgrimage.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'But when from highmost pitch with weary car',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Like feeble age he reeleth from the day,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"The eyes, 'fore duteous, now converted are\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'From his low tract and look another way.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'So thou, thyself outgoing in thy noon,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Unlooked on diest unless thou get a son.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"Music to hear, why hear'st thou music sadly?\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Sweets with sweets war not, joy delights in joy.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"Why lov'st thou that which thou receiv'st not gladly,\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"Or else receiv'st with pleasure thine annoy?\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'If the true concord of well-tuned sounds,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'By unions married, do offend thine ear,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'They do but sweetly chide thee, who confounds',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'In singleness the parts that thou shouldst bear.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Mark how one string, sweet husband to another,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Strikes each in each by mutual ordering,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Resembling sire and child and happy mother',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Who, all in one, one pleasing note do sing;',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Whose speechless song, being many, seeming one,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Sings this to thee: \"Thou single wilt prove none.\"',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"Is it for fear to wet a widow's eye\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"That thou consum'st thyself in single life?\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Ah, if thou issueless shalt hap to die,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'The world will wail thee like a makeless wife;',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'The world will be thy widow and still weep',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'That thou no form of thee hast left behind,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'When every private widow well may keep,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"By children's eyes, her husband's shape in mind.\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Look what an unthrift in the world doth spend',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Shifts but his place, for still the world enjoys it;',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"But beauty's waste hath in the world an end,\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And, kept unused, the user so destroys it.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'No love toward others in that bosom sits',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"That on himself such murd'rous shame commits.\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"For shame deny that thou bear'st love to any,\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Who for thyself art so unprovident.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Grant, if thou wilt, thou art beloved of many,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"But that thou none lov'st is most evident.\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"For thou art so possessed with murd'rous hate\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"That 'gainst thyself thou stick'st not to conspire,\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Seeking that beauteous roof to ruinate',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Which to repair should be thy chief desire.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'O, change thy thought, that I may change my mind.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Shall hate be fairer lodged than gentle love?',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Be as thy presence is, gracious and kind,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Or to thyself at least kind-hearted prove.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Make thee another self for love of me,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'That beauty still may live in thine or thee.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"As fast as thou shalt wane, so fast thou grow'st\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'In one of thine, from that which thou departest;',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"And that fresh blood which youngly thou bestow'st\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Thou mayst call thine when thou from youth convertest.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Herein lives wisdom, beauty, and increase;',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Without this, folly, age, and cold decay.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'If all were minded so, the times should cease,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And threescore year would make the world away.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Let those whom nature hath not made for store,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Harsh, featureless, and rude, barrenly perish;',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Look whom she best endowed she gave the more,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Which bounteous gift thou shouldst in bounty cherish.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'She carved thee for her seal, and meant thereby',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Thou shouldst print more, not let that copy die.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'When I do count the clock that tells the time',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And see the brave day sunk in hideous night,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'When I behold the violet past prime',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"And sable curls all silvered o'er with white;\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'When lofty trees I see barren of leaves,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Which erst from heat did canopy the herd,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"And summer's green all girded up in sheaves\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Borne on the bier with white and bristly beard;',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Then of thy beauty do I question make',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'That thou among the wastes of time must go,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Since sweets and beauties do themselves forsake',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And die as fast as they see others grow;',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"And nothing 'gainst Time's scythe can make defense\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Save breed, to brave him when he takes thee hence.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'O, that you were your self! But, love, you are',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'No longer yours than you yourself here live;',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Against this coming end you should prepare,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And your sweet semblance to some other give.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'So should that beauty which you hold in lease',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Find no determination; then you were',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"Your self again after yourself's decease\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'When your sweet issue your sweet form should bear.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Who lets so fair a house fall to decay,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Which husbandry in honor might uphold',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"Against the stormy gusts of winter's day\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"And barren rage of death's eternal cold?\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'O, none but unthrifts, dear my love, you know.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'You had a father; let your son say so.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Not from the stars do I my judgment pluck,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And yet methinks I have astronomy--',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'But not to tell of good or evil luck,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"Of plagues, of dearths, or seasons' quality;\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Nor can I fortune to brief minutes tell,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Pointing to each his thunder, rain, and wind,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Or say with princes if it shall go well',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'By oft predict that I in heaven find.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'But from thine eyes my knowledge I derive,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And, constant stars, in them I read such art',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'As truth and beauty shall together thrive',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'If from thyself to store thou wouldst convert;',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Or else of thee this I prognosticate:',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"Thy end is truth's and beauty's doom and date.\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'When I consider everything that grows',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Holds in perfection but a little moment,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'That this huge stage presenteth nought but shows',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Whereon the stars in secret influence comment;',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'When I perceive that men as plants increase,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Cheered and checked even by the selfsame sky,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Vaunt in their youthful sap, at height decrease,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And wear their brave state out of memory;',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Then the conceit of this inconstant stay',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Sets you most rich in youth before my sight,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Where wasteful Time debateth with Decay',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'To change your day of youth to sullied night;',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And, all in war with Time for love of you,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'As he takes from you, I engraft you new.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'But wherefore do not you a mightier way',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Make war upon this bloody tyrant Time,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And fortify yourself in your decay',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'With means more blessed than my barren rhyme?',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Now stand you on the top of happy hours,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And many maiden gardens, yet unset,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'With virtuous wish would bear your living flowers,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Much liker than your painted counterfeit.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'So should the lines of life that life repair',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"Which this time's pencil or my pupil pen\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Neither in inward worth nor outward fair',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Can make you live yourself in eyes of men.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'To give away yourself keeps yourself still,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And you must live, drawn by your own sweet skill.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Who will believe my verse in time to come',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'If it were filled with your most high deserts?',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Though yet, heaven knows, it is but as a tomb',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Which hides your life and shows not half your parts.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'If I could write the beauty of your eyes',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And in fresh numbers number all your graces,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'The age to come would say \"This poet lies;',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Such heavenly touches ne\\'er touched earthly faces.\"',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'So should my papers, yellowed with their age,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Be scorned, like old men of less truth than tongue,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"And your true rights be termed a poet's rage\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And stretched meter of an antique song.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'But were some child of yours alive that time,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'You should live twice--in it and in my rhyme.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"Shall I compare thee to a summer's day?\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Thou art more lovely and more temperate.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Rough winds do shake the darling buds of May,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"And summer's lease hath all too short a date.\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Sometime too hot the eye of heaven shines,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And often is his gold complexion dimmed;',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And every fair from fair sometime declines,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"By chance or nature's changing course untrimmed.\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'But thy eternal summer shall not fade',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"Nor lose possession of that fair thou ow'st,\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"Nor shall Death brag thou wand'rest in his shade,\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"When in eternal lines to time thou grow'st.\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'So long as men can breathe or eyes can see,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'So long lives this, and this gives life to thee.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"Devouring Time, blunt thou the lion's paws\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And make the Earth devour her own sweet brood;',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"Pluck the keen teeth from the fierce tiger's jaws,\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And burn the long-lived phoenix in her blood;',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"Make glad and sorry seasons as thou fleet'st\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"And do whate'er thou wilt, swift-footed Time,\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'To the wide world and all her fading sweets.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'But I forbid thee one most heinous crime:',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"O, carve not with thy hours my love's fair brow,\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Nor draw no lines there with thine antique pen;',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Him in thy course untainted do allow',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"For beauty's pattern to succeeding men.\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Yet do thy worst, old Time; despite thy wrong,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'My love shall in my verse ever live young.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"A woman's face with Nature's own hand painted\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Hast thou, the master mistress of my passion;',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"A woman's gentle heart, but not acquainted\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"With shifting change, as is false women's fashion;\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'An eye more bright than theirs, less false in rolling,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Gilding the object whereupon it gazeth;',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'A man in hue all hues in his controlling,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"Which steals men's eyes and women's souls amazeth.\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And for a woman wert thou first created,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Till Nature as she wrought thee fell a-doting,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And by addition me of thee defeated',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'By adding one thing to my purpose nothing.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"But since she pricked thee out for women's pleasure,\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"Mine be thy love, and thy love's use their treasure.\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'So is it not with me as with that muse',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Stirred by a painted beauty to his verse,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Who heaven itself for ornament doth use',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And every fair with his fair doth rehearse,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Making a couplement of proud compare',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"With sun and moon, with earth and sea's rich gems,\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"With April's firstborn flowers and all things rare\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"That heaven's air in this huge rondure hems.\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'O, let me, true in love, but truly write,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And then believe me, my love is as fair',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"As any mother's child, though not so bright\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"As those gold candles fixed in heaven's air.\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Let them say more that like of hearsay well;',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'I will not praise that purpose not to sell.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'My glass shall not persuade me I am old',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'So long as youth and thou are of one date,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"But when in thee Time's furrows I behold,\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Then look I death my days should expiate.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'For all that beauty that doth cover thee',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Is but the seemly raiment of my heart,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Which in thy breast doth live, as thine in me;',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'How can I then be elder than thou art?',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'O, therefore, love, be of thyself so wary',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'As I not for myself but for thee will,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Bearing thy heart, which I will keep so chary',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'As tender nurse her babe from faring ill.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Presume not on thy heart when mine is slain.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"Thou gav'st me thine not to give back again.\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'As an unperfect actor on the stage',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Who with his fear is put beside his part,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Or some fierce thing replete with too much rage,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"Whose strength's abundance weakens his own heart;\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'So I for fear of trust forget to say',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"The perfect ceremony of love's rite,\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"And in mine own love's strength seem to decay,\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"O'ercharged with burden of mine own love's might.\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'O, let my books be then the eloquence',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And dumb presagers of my speaking breast,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Who plead for love and look for recompense',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'More than that tongue that more hath more expressed.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'O, learn to read what silent love hath writ.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"To hear with eyes belongs to love's fine wit.\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Mine eye hath played the painter and hath stelled',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"Thy beauty's form in table of my heart;\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"My body is the frame wherein 'tis held,\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"And perspective it is best painter's art.\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'For through the painter must you see his skill',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'To find where your true image pictured lies,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"Which in my bosom's shop is hanging still,\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'That hath his windows glazed with thine eyes.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Now see what good turns eyes for eyes have done:',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Mine eyes have drawn thy shape, and thine for me',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Are windows to my breast, wherethrough the sun',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Delights to peep, to gaze therein on thee.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Yet eyes this cunning want to grace their art:',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'They draw but what they see, know not the heart.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Let those who are in favor with their stars',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Of public honor and proud titles boast,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Whilst I, whom fortune of such triumph bars,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Unlooked for joy in that I honor most.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"Great princes' favorites their fair leaves spread\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"But as the marigold at the sun's eye,\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And in themselves their pride lies buried,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'For at a frown they in their glory die.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'The painful warrior famoused for worth,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'After a thousand victories once foiled,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Is from the book of honor razed quite,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And all the rest forgot for which he toiled.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Then happy I, that love and am beloved',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Where I may not remove nor be removed.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Lord of my love, to whom in vassalage',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Thy merit hath my duty strongly knit,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'To thee I send this written embassage',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'To witness duty, not to show my wit;',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Duty so great, which wit so poor as mine',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'May make seem bare, in wanting words to show it,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'But that I hope some good conceit of thine',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"In thy soul's thought, all naked, will bestow it;\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Till whatsoever star that guides my moving',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Points on me graciously with fair aspect,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And puts apparel on my tattered loving',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'To show me worthy of thy sweet respect.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Then may I dare to boast how I do love thee;',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Till then, not show my head where thou mayst prove me.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Weary with toil, I haste me to my bed,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'The dear repose for limbs with travel tired,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'But then begins a journey in my head',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"To work my mind when body's work's expired.\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'For then my thoughts, from far where I abide,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Intend a zealous pilgrimage to thee,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And keep my drooping eyelids open wide,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Looking on darkness which the blind do see;',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"Save that my soul's imaginary sight\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Presents thy shadow to my sightless view,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Which like a jewel hung in ghastly night',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Makes black night beauteous and her old face new.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Lo, thus, by day my limbs, by night my mind,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'For thee and for myself no quiet find.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'How can I then return in happy plight',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'That am debarred the benefit of rest,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"When day's oppression is not eased by night,\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'But day by night and night by day oppressed;',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"And each, though enemies to either's reign,\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Do in consent shake hands to torture me,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'The one by toil, the other to complain',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'How far I toil, still farther off from thee?',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'I tell the day to please him thou art bright',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And dost him grace when clouds do blot the heaven;',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'So flatter I the swart complexioned night,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"When sparkling stars twire not, thou gild'st the even.\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'But day doth daily draw my sorrows longer,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"And night doth nightly make grief's length seem stronger.\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"When in disgrace with fortune and men's eyes,\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'I all alone beweep my outcast state,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And trouble deaf heaven with my bootless cries,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And look upon myself and curse my fate,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Wishing me like to one more rich in hope,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Featured like him, like him with friends possessed,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"Desiring this man's art and that man's scope,\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'With what I most enjoy contented least;',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Yet in these thoughts myself almost despising,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Haply I think on thee, and then my state,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Like to the lark at break of day arising',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"From sullen earth, sings hymns at heaven's gate;\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'For thy sweet love remembered such wealth brings',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'That then I scorn to change my state with kings.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'When to the sessions of sweet silent thought',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'I summon up remembrance of things past,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'I sigh the lack of many a thing I sought,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"And with old woes new wail my dear time's waste;\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Then can I drown an eye, unused to flow,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"For precious friends hid in death's dateless night,\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"And weep afresh love's long since canceled woe,\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"And moan th' expense of many a vanished sight.\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Then can I grieve at grievances foregone,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"And heavily from woe to woe tell o'er\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'The sad account of fore-bemoaned moan,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Which I new pay as if not paid before.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'But if the while I think on thee, dear friend,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'All losses are restored and sorrows end.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Thy bosom is endeared with all hearts',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Which I by lacking have supposed dead,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"And there reigns love and all love's loving parts,\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And all those friends which I thought buried.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'How many a holy and obsequious tear',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"Hath dear religious love stol'n from mine eye,\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'As interest of the dead, which now appear',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'But things removed that hidden in thee lie.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Thou art the grave where buried love doth live,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Hung with the trophies of my lovers gone,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Who all their parts of me to thee did give;',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'That due of many now is thine alone.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Their images I loved I view in thee,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And thou, all they, hast all the all of me.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'If thou survive my well-contented day',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'When that churl Death my bones with dust shall cover,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And shalt by fortune once more resurvey',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'These poor rude lines of thy deceased lover,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"Compare them with the bett'ring of the time,\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And though they be outstripped by every pen,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Reserve them for my love, not for their rhyme,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Exceeded by the height of happier men.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'O, then vouchsafe me but this loving thought:',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': '\"Had my friend\\'s muse grown with this growing age,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'A dearer birth than this his love had brought',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'To march in ranks of better equipage.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'But since he died and poets better prove,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Theirs for their style I\\'ll read, his for his love.\"',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Full many a glorious morning have I seen',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Flatter the mountain tops with sovereign eye,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Kissing with golden face the meadows green,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Gilding pale streams with heavenly alchemy,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Anon permit the basest clouds to ride',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'With ugly rack on his celestial face,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And from the forlorn world his visage hide,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Stealing unseen to west with this disgrace.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Even so my sun one early morn did shine',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'With all-triumphant splendor on my brow,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'But, out alack, he was but one hour mine;',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'The region cloud hath masked him from me now.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Yet him for this my love no whit disdaineth;',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"Suns of the world may stain when heaven's sun staineth.\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Why didst thou promise such a beauteous day',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And make me travel forth without my cloak,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"To let base clouds o'ertake me in my way,\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"Hiding thy brav'ry in their rotten smoke?\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"'Tis not enough that through the cloud thou break\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'To dry the rain on my storm-beaten face,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'For no man well of such a salve can speak',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'That heals the wound and cures not the disgrace.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Nor can thy shame give physic to my grief;',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Though thou repent, yet I have still the loss.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"Th' offender's sorrow lends but weak relief\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"To him that bears the strong offense's cross.\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Ah, but those tears are pearl which thy love sheds,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And they are rich and ransom all ill deeds.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'No more be grieved at that which thou hast done.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Roses have thorns, and silver fountains mud;',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Clouds and eclipses stain both moon and sun,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And loathsome canker lives in sweetest bud.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'All men make faults, and even I in this,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Authorizing thy trespass with compare,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Myself corrupting salving thy amiss,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Excusing thy sins more than thy sins are.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'For to thy sensual fault I bring in sense--',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Thy adverse party is thy advocate--',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"And 'gainst myself a lawful plea commence.\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Such civil war is in my love and hate',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'That I an accessary needs must be',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'To that sweet thief which sourly robs from me.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Let me confess that we two must be twain',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Although our undivided loves are one;',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'So shall those blots that do with me remain,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Without thy help, by me be borne alone.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'In our two loves there is but one respect,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Though in our lives a separable spite,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"Which though it alter not love's sole effect,\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"Yet doth it steal sweet hours from love's delight.\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'I may not evermore acknowledge thee,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Lest my bewailed guilt should do thee shame,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Nor thou with public kindness honor me',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Unless thou take that honor from thy name.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'But do not so. I love thee in such sort',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'As, thou being mine, mine is thy good report.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'As a decrepit father takes delight',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'To see his active child do deeds of youth,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"So I, made lame by fortune's dearest spite,\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Take all my comfort of thy worth and truth.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'For whether beauty, birth, or wealth, or wit,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Or any of these all, or all, or more,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Entitled in thy parts do crowned sit,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'I make my love engrafted to this store.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'So then I am not lame, poor, nor despised',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Whilst that this shadow doth such substance give',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'That I in thy abundance am sufficed',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And by a part of all thy glory live.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Look what is best, that best I wish in thee.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'This wish I have, then ten times happy me.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'How can my muse want subject to invent',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"While thou dost breathe that pour'st into my verse\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Thine own sweet argument, too excellent',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'For every vulgar paper to rehearse?',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'O, give thyself the thanks if aught in me',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Worthy perusal stand against thy sight,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"For who's so dumb that cannot write to thee\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'When thou thyself dost give invention light?',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Be thou the tenth muse, ten times more in worth',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Than those old nine which rhymers invocate;',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And he that calls on thee, let him bring forth',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Eternal numbers to outlive long date.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'If my slight muse do please these curious days,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'The pain be mine, but thine shall be the praise.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'O, how thy worth with manners may I sing',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'When thou art all the better part of me?',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'What can mine own praise to mine own self bring,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"And what is 't but mine own when I praise thee?\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Even for this let us divided live',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And our dear love lose name of single one,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'That by this separation I may give',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"That due to thee which thou deserv'st alone.\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'O absence, what a torment wouldst thou prove',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Were it not thy sour leisure gave sweet leave',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'To entertain the time with thoughts of love,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Which time and thoughts so sweetly doth deceive,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And that thou teachest how to make one twain',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'By praising him here who doth hence remain.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Take all my loves, my love, yea, take them all.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'What hast thou then more than thou hadst before?',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'No love, my love, that thou mayst true love call;',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'All mine was thine before thou hadst this more.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Then, if for my love thou my love receivest,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'I cannot blame thee for my love thou usest;',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'But yet be blamed if thou thyself deceivest',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'By willful taste of what thyself refusest.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"I do forgive thy robb'ry, gentle thief,\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Although thou steal thee all my poverty;',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And yet love knows it is a greater grief',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"To bear love's wrong than hate's known injury.\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Lascivious grace, in whom all ill well shows,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Kill me with spites, yet we must not be foes.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Those pretty wrongs that liberty commits',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'When I am sometime absent from thy heart,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Thy beauty and thy years full well befits,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'For still temptation follows where thou art.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Gentle thou art, and therefore to be won;',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Beauteous thou art, therefore to be assailed;',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"And when a woman woos, what woman's son\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Will sourly leave her till he have prevailed?',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Ay me, but yet thou mightst my seat forbear,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And chide thy beauty and thy straying youth,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Who lead thee in their riot even there',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Where thou art forced to break a twofold truth:',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Hers, by thy beauty tempting her to thee,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Thine, by thy beauty being false to me.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'That thou hast her, it is not all my grief,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And yet it may be said I loved her dearly;',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'That she hath thee is of my wailing chief,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'A loss in love that touches me more nearly.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Loving offenders, thus I will excuse ye:',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"Thou dost love her because thou know'st I love her,\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And for my sake even so doth she abuse me,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"Suff'ring my friend for my sake to approve her.\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"If I lose thee, my loss is my love's gain,\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And losing her, my friend hath found that loss;',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Both find each other, and I lose both twain,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And both for my sake lay on me this cross.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"But here's the joy: my friend and I are one;\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Sweet flattery! then she loves but me alone.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'When most I wink, then do mine eyes best see,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'For all the day they view things unrespected;',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'But when I sleep, in dreams they look on thee',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And, darkly bright, are bright in dark directed.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Then thou whose shadow shadows doth make bright,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"How would thy shadow's form form happy show\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'To the clear day with thy much clearer light',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'When to unseeing eyes thy shade shines so!',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'How would, I say, mine eyes be blessed made',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'By looking on thee in the living day,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'When in dead night thy fair imperfect shade',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Through heavy sleep on sightless eyes doth stay!',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'All days are nights to see till I see thee,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And nights bright days when dreams do show thee me.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'If the dull substance of my flesh were thought,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Injurious distance should not stop my way,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'For then, despite of space, I would be brought',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'From limits far remote, where thou dost stay.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'No matter then although my foot did stand',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Upon the farthest earth removed from thee,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'For nimble thought can jump both sea and land',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'As soon as think the place where he would be.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'But, ah, thought kills me that I am not thought,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'To leap large lengths of miles when thou art gone,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'But that, so much of earth and water wrought,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"I must attend time's leisure with my moan;\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Receiving nought by elements so slow',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"But heavy tears, badges of either's woe.\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'The other two, slight air and purging fire,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Are both with thee, wherever I abide;',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'The first my thought, the other my desire,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'These present-absent with swift motion slide.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'For when these quicker elements are gone',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'In tender embassy of love to thee,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'My life, being made of four, with two alone',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Sinks down to death, oppressed with melancholy;',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"Until life's composition be recured\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'By those swift messengers returned from thee,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Who even but now come back again, assured',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Of thy fair health, recounting it to me.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'This told, I joy; but then, no longer glad,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'I send them back again and straight grow sad.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Mine eye and heart are at a mortal war',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'How to divide the conquest of thy sight.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"Mine eye my heart thy picture's sight would bar,\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'My heart mine eye the freedom of that right.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'My heart doth plead that thou in him dost lie,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'A closet never pierced with crystal eyes;',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'But the defendant doth that plea deny,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And says in him thy fair appearance lies.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"To 'cide this title is impaneled\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'A quest of thoughts, all tenants to the heart,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And by their verdict is determined',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"The clear eyes' moiety and the dear heart's part,\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"As thus: mine eyes' due is thy outward part,\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"And my heart's right, thy inward love of heart.\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Betwixt mine eye and heart a league is took,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And each doth good turns now unto the other.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'When that mine eye is famished for a look,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Or heart in love with sighs himself doth smother,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"With my love's picture then my eye doth feast\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And to the painted banquet bids my heart.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"Another time mine eye is my heart's guest\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And in his thoughts of love doth share a part.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'So, either by thy picture or my love,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Thyself away are present still with me;',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'For thou no farther than my thoughts canst move,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And I am still with them, and they with thee;',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Or, if they sleep, thy picture in my sight',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"Awakes my heart to heart's and eye's delight.\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'How careful was I, when I took my way,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Each trifle under truest bars to thrust,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'That to my use it might unused stay',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'From hands of falsehood, in sure wards of trust!',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'But thou, to whom my jewels trifles are,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Most worthy comfort, now my greatest grief,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Thou best of dearest and mine only care',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Art left the prey of every vulgar thief.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Thee have I not locked up in any chest,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Save where thou art not, though I feel thou art,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Within the gentle closure of my breast,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'From whence at pleasure thou mayst come and part;',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"And even thence thou wilt be stol'n, I fear,\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'For truth proves thievish for a prize so dear.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Against that time, if ever that time come,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'When I shall see thee frown on my defects,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Whenas thy love hath cast his utmost sum,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Called to that audit by advised respects;',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Against that time when thou shalt strangely pass',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And scarcely greet me with that sun thine eye,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'When love, converted from the thing it was,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Shall reasons find of settled gravity;',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Against that time do I ensconce me here',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Within the knowledge of mine own desert,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And this my hand against myself uprear',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'To guard the lawful reasons on thy part.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'To leave poor me thou hast the strength of laws,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Since why to love I can allege no cause.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'How heavy do I journey on the way,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"When what I seek, my weary travel's end,\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Doth teach that ease and that repose to say',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': '\"Thus far the miles are measured from thy friend.\"',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'The beast that bears me, tired with my woe,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Plods dully on, to bear that weight in me,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'As if by some instinct the wretch did know',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'His rider loved not speed, being made from thee.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'The bloody spur cannot provoke him on',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'That sometimes anger thrusts into his hide,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Which heavily he answers with a groan,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'More sharp to me than spurring to his side;',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'For that same groan doth put this in my mind:',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'My grief lies onward and my joy behind.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Thus can my love excuse the slow offense',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Of my dull bearer when from thee I speed:',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'From where thou art, why should I haste me thence?',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Till I return, of posting is no need.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'O, what excuse will my poor beast then find',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'When swift extremity can seem but slow?',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Then should I spur, though mounted on the wind;',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'In winged speed no motion shall I know.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Then can no horse with my desire keep pace;',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"Therefore desire, of perfect'st love being made,\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Shall neigh no dull flesh in his fiery race.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'But love for love thus shall excuse my jade:',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': '\"Since from thee going he went willful slow,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Towards thee I\\'ll run, and give him leave to go.\"',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'So am I as the rich whose blessed key',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Can bring him to his sweet up-locked treasure,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"The which he will not ev'ry hour survey,\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'For blunting the fine point of seldom pleasure.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Therefore are feasts so solemn and so rare,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Since seldom coming in the long year set,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Like stones of worth they thinly placed are,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Or captain jewels in the carcanet.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'So is the time that keeps you as my chest,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Or as the wardrobe which the robe doth hide',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'To make some special instant special blessed',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'By new unfolding his imprisoned pride.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Blessed are you whose worthiness gives scope,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Being had, to triumph, being lacked, to hope.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'What is your substance, whereof are you made,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'That millions of strange shadows on you tend?',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Since everyone hath, every one, one shade,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And you, but one, can every shadow lend.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Describe Adonis, and the counterfeit',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Is poorly imitated after you;', 'type': 'single', 'num_lines': 1},\n",
       " {'text': \"On Helen's cheek all art of beauty set,\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And you in Grecian tires are painted new.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Speak of the spring and foison of the year;',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'The one doth shadow of your beauty show,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'The other as your bounty doth appear,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And you in every blessed shape we know.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'In all external grace you have some part,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'But you like none, none you, for constant heart.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'O, how much more doth beauty beauteous seem',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'By that sweet ornament which truth doth give.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'The rose looks fair, but fairer we it deem',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'For that sweet odor which doth in it live.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'The canker blooms have full as deep a dye',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'As the perfumed tincture of the roses,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Hang on such thorns, and play as wantonly',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"When summer's breath their masked buds discloses;\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'But, for their virtue only is their show,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'They live unwooed and unrespected fade,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Die to themselves. Sweet roses do not so;',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Of their sweet deaths are sweetest odors made.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And so of you, beauteous and lovely youth,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'When that shall vade, by verse distils your truth.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Not marble nor the gilded monuments',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Of princes shall outlive this powerful rhyme,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'But you shall shine more bright in these contents',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Than unswept stone besmeared with sluttish time.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'When wasteful war shall statues overturn,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And broils root out the work of masonry,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"Nor Mars his sword nor war's quick fire shall burn\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'The living record of your memory.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"'Gainst death and all oblivious enmity\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Shall you pace forth; your praise shall still find room',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Even in the eyes of all posterity',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'That wear this world out to the ending doom.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'So, till the judgment that yourself arise,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"You live in this, and dwell in lovers' eyes.\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Sweet love, renew thy force. Be it not said',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Thy edge should blunter be than appetite,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Which but today by feeding is allayed,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Tomorrow sharpened in his former might.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'So, love, be thou. Although today thou fill',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Thy hungry eyes even till they wink with fullness,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Tomorrow see again, and do not kill',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'The spirit of love with a perpetual dullness.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"Let this sad int'rim like the ocean be\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Which parts the shore where two contracted new',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Come daily to the banks, that, when they see',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Return of love, more blessed may be the view.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Or call it winter, which being full of care',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"Makes summer's welcome, thrice more wished, more rare.\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Being your slave, what should I do but tend',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Upon the hours and times of your desire?',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'I have no precious time at all to spend',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Nor services to do till you require.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Nor dare I chide the world-without-end hour',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Whilst I, my sovereign, watch the clock for you,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Nor think the bitterness of absence sour',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'When you have bid your servant once adieu.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Nor dare I question with my jealous thought',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Where you may be, or your affairs suppose,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'But, like a sad slave, stay and think of nought',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Save where you are how happy you make those.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'So true a fool is love that in your will,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Though you do anything, he thinks no ill.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'That god forbid, that made me first your slave,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'I should in thought control your times of pleasure,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"Or at your hand th' account of hours to crave,\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Being your vassal bound to stay your leisure.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'O, let me suffer, being at your beck,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"Th' imprisoned absence of your liberty,\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And patience, tame to sufferance, bide each check',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Without accusing you of injury.', 'type': 'single', 'num_lines': 1},\n",
       " {'text': 'Be where you list, your charter is so strong',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'That you yourself may privilege your time',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'To what you will; to you it doth belong',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Yourself to pardon of self-doing crime.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'I am to wait, though waiting so be hell,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Not blame your pleasure, be it ill or well.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'If there be nothing new, but that which is',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Hath been before, how are our brains beguiled,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Which, laboring for invention, bear amiss',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'The second burden of a former child.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'O, that record could with a backward look,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Even of five hundred courses of the sun,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Show me your image in some antique book,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Since mind at first in character was done,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'That I might see what the old world could say',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'To this composed wonder of your frame;',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"Whether we are mended, or whe'er better they,\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Or whether revolution be the same.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'O, sure I am the wits of former days',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'To subjects worse have given admiring praise.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Like as the waves make towards the pebbled shore,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'So do our minutes hasten to their end,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Each changing place with that which goes before;',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'In sequent toil all forwards do contend.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Nativity, once in the main of light,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Crawls to maturity, wherewith being crowned,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"Crooked eclipses 'gainst his glory fight,\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And Time that gave doth now his gift confound.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Time doth transfix the flourish set on youth',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"And delves the parallels in beauty's brow,\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"Feeds on the rarities of Nature's truth,\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And nothing stands but for his scythe to mow.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And yet to times in hope my verse shall stand,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Praising thy worth, despite his cruel hand.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Is it thy will thy image should keep open',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'My heavy eyelids to the weary night?',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Dost thou desire my slumbers should be broken',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'While shadows like to thee do mock my sight?',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"Is it thy spirit that thou send'st from thee\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'So far from home into my deeds to pry,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'To find out shames and idle hours in me,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'The scope and tenor of thy jealousy?',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'O, no. Thy love, though much, is not so great.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'It is my love that keeps mine eye awake,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Mine own true love that doth my rest defeat',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'To play the watchman ever for thy sake.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'For thee watch I whilst thou dost wake elsewhere,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'From me far off, with others all too near.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Sin of self-love possesseth all mine eye',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And all my soul and all my every part;',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And for this sin there is no remedy,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'It is so grounded inward in my heart.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Methinks no face so gracious is as mine,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'No shape so true, no truth of such account,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And for myself mine own worth do define',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'As I all other in all worths surmount.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'But when my glass shows me myself indeed',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Beated and chopped with tanned antiquity,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Mine own self-love quite contrary I read;',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Self so self-loving were iniquity.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"'Tis thee, myself, that for myself I praise,\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Painting my age with beauty of thy days.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Against my love shall be, as I am now,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"With Time's injurious hand crushed and o'erworn;\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'When hours have drained his blood and filled his brow',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'With lines and wrinkles; when his youthful morn',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"Hath traveled on to age's steepy night,\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"And all those beauties whereof now he's king\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Are vanishing, or vanished out of sight,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Stealing away the treasure of his spring;',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'For such a time do I now fortify',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"Against confounding age's cruel knife,\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'That he shall never cut from memory',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"My sweet love's beauty, though my lover's life.\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'His beauty shall in these black lines be seen,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And they shall live, and he in them still green.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"When I have seen by Time's fell hand defaced\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'The rich proud cost of outworn buried age;',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'When sometime lofty towers I see down-razed',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And brass eternal slave to mortal rage;',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'When I have seen the hungry ocean gain',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Advantage on the kingdom of the shore,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"And the firm soil win of the wat'ry main,\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Increasing store with loss and loss with store;',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'When I have seen such interchange of state,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Or state itself confounded to decay,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Ruin hath taught me thus to ruminate,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'That Time will come and take my love away.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'This thought is as a death, which cannot choose',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'But weep to have that which it fears to lose.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Since brass, nor stone, nor earth, nor boundless sea',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"But sad mortality o'ersways their power,\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'How with this rage shall beauty hold a plea,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Whose action is no stronger than a flower?',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"O, how shall summer's honey breath hold out\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"Against the wrackful siege of batt'ring days,\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'When rocks impregnable are not so stout',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Nor gates of steel so strong, but Time decays?',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'O, fearful meditation! Where, alack,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"Shall Time's best jewel from Time's chest lie hid?\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Or what strong hand can hold his swift foot back,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Or who his spoil of beauty can forbid?',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'O, none, unless this miracle have might,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'That in black ink my love may still shine bright.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Tired with all these, for restful death I cry:',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'As, to behold desert a beggar born,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And needy nothing trimmed in jollity,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And purest faith unhappily forsworn,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And gilded honor shamefully misplaced,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And maiden virtue rudely strumpeted,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And right perfection wrongfully disgraced,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And strength by limping sway disabled,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And art made tongue-tied by authority,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And folly, doctor-like, controlling skill,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And simple truth miscalled simplicity,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And captive good attending captain ill.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Tired with all these, from these would I be gone,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Save that, to die, I leave my love alone.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Ah, wherefore with infection should he live,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And with his presence grace impiety,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'That sin by him advantage should achieve',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And lace itself with his society?',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Why should false painting imitate his cheek',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And steal dead seeing of his living hue?',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Why should poor beauty indirectly seek',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Roses of shadow, since his rose is true?',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Why should he live, now Nature bankrout is,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Beggared of blood to blush through lively veins,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'For she hath no exchequer now but his,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And, proud of many, lives upon his gains?',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'O, him she stores, to show what wealth she had',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'In days long since, before these last so bad.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Thus is his cheek the map of days outworn,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'When beauty lived and died as flowers do now,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Before these bastard signs of fair were borne,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Or durst inhabit on a living brow;',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Before the golden tresses of the dead,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'The right of sepulchers, were shorn away',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'To live a second life on second head,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"Ere beauty's dead fleece made another gay.\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'In him those holy antique hours are seen,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Without all ornament, itself and true,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"Making no summer of another's green,\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Robbing no old to dress his beauty new.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And him as for a map doth Nature store,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'To show false art what beauty was of yore.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"Those parts of thee that the world's eye doth view\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Want nothing that the thought of hearts can mend.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'All tongues, the voice of souls, give thee that due,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"Utt'ring bare truth, even so as foes commend.\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Thy outward thus with outward praise is crowned,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'But those same tongues that give thee so thine own',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'In other accents do this praise confound',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'By seeing farther than the eye hath shown.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'They look into the beauty of thy mind,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And that, in guess, they measure by thy deeds;',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Then, churls, their thoughts, although their eyes were kind,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'To thy fair flower add the rank smell of weeds.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'But why thy odor matcheth not thy show,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'The soil is this, that thou dost common grow.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'That thou art blamed shall not be thy defect,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"For slander's mark was ever yet the fair.\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'The ornament of beauty is suspect,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"A crow that flies in heaven's sweetest air.\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'So thou be good, slander doth but approve',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Thy worth the greater, being wooed of time,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'For canker vice the sweetest buds doth love,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': \"And thou present'st a pure unstained prime.\",\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Thou hast passed by the ambush of young days,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Either not assailed, or victor being charged;',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Yet this thy praise cannot be so thy praise',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'To tie up envy, evermore enlarged.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'If some suspect of ill masked not thy show,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Then thou alone kingdoms of hearts shouldst owe.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'No longer mourn for me when I am dead',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Than you shall hear the surly sullen bell',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Give warning to the world that I am fled',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'From this vile world with vilest worms to dwell.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Nay, if you read this line, remember not',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'The hand that writ it, for I love you so',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'That I in your sweet thoughts would be forgot,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'If thinking on me then should make you woe.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'O, if, I say, you look upon this verse',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'When I, perhaps, compounded am with clay,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Do not so much as my poor name rehearse,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'But let your love even with my life decay,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Lest the wise world should look into your moan',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'And mock you with me after I am gone.',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'O, lest the world should task you to recite',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'What merit lived in me that you should love,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'After my death, dear love, forget me quite,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'For you in me can nothing worthy prove;',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'Unless you would devise some virtuous lie,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " {'text': 'To do more for me than mine own desert,',\n",
       "  'type': 'single',\n",
       "  'num_lines': 1},\n",
       " ...]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_samples = prepare_mixed_samples(cleaned_data, include_single=True, include_couplet=True, include_quatrain=False, include_sonnet=False)\n",
    "all_data_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5de632be-ccc1-49ab-9310-1063615685fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'single': 2183, 'couplet': 1091})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(sample['type'] for sample in all_data_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25fe4b5-0529-4c4a-8fd0-dd47abc11010",
   "metadata": {},
   "source": [
    "* Now let's create shakespeare dataset class which will take all samples and precompute and then return contextualized BERT embedding for text and also for first n POS (Part of speech) words\n",
    "* Here for text embeddings (i.e. embeddings for samples) we are contextualizing from whole text (sample) and for POS embedding we are contextualizing from POS word only as at time of generation POS embeddings are going to be contextualized from POS words so to keep things similar for POS we are contextlaizing based on POS words only\n",
    "* We also add normalization to embedding because diffusion model works best with normalized data\n",
    "* Noise that we add to this data is sampled from gausian distribution having mean of 0 and standard deviation of 1 so normalizing embedding data leads to stable training and also match noise mean and standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e57aed83-5f91-4d49-90e0-a981b8683022",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShakespeareDiffusionDataset(Dataset):\n",
    "    \"\"\"Dataset with normalization for diffusion which returns BERT embeddings\"\"\"\n",
    "    def __init__(self, samples, model_name='bert-base-uncased', max_length=64, n_pos_words=3, device='cuda'):\n",
    "        self.samples = samples\n",
    "        self.model_name = model_name\n",
    "        self.max_length = max_length\n",
    "        self.n_pos_words = n_pos_words\n",
    "        self.device = device\n",
    "        # Loading model and tokenizer\n",
    "        print(f\"\\nLoading BERT model: {model_name}\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModel.from_pretrained(model_name).to(device)\n",
    "        self.model.eval()\n",
    "        self.hidden_dim = self.model.config.hidden_size\n",
    "        print(f\"Hidden dimension: {self.hidden_dim}\")\n",
    "        # Precomputing all embeddings\n",
    "        print(f\"Pre-computing embeddings for {len(samples)} samples...\")\n",
    "        self.raw_embeddings, self.pos_embeddings = self._precompute_all()\n",
    "        # Calculating normalization statistics from the data\n",
    "        print(\"Calculating normalization statistics.\")\n",
    "        all_emb = torch.stack(self.raw_embeddings)\n",
    "        self.emb_mean = all_emb.mean().item()\n",
    "        self.emb_std = all_emb.std().item()\n",
    "        print(f\"Raw embedding stats: mean={self.emb_mean:.4f}, std={self.emb_std:.4f}\")\n",
    "        # Normalizing embeddings to mean=0, std=1\n",
    "        self.embeddings = [(e - self.emb_mean) / self.emb_std for e in self.raw_embeddings]\n",
    "        # Verifying normalization\n",
    "        all_norm = torch.stack(self.embeddings)\n",
    "        print(f\"  Normalized stats: mean={all_norm.mean():.4f}, std={all_norm.std():.4f}\")\n",
    "        print(f\"Done! Dataset ready.\\n\")\n",
    "        # Freeing GPU memory\n",
    "        del self.model\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    def _get_text_embedding(self, text):\n",
    "        \"\"\"Function to get BERT contextual embeddings for text\"\"\"\n",
    "        encoded = self.tokenizer(text, return_tensors='pt', padding='max_length', truncation=True, max_length=self.max_length).to(self.device)\n",
    "        outputs = self.model(**encoded)\n",
    "        embedding = outputs.last_hidden_state.squeeze(0).cpu()\n",
    "        return embedding\n",
    "    \n",
    "    def _get_pos_embedding(self, text):\n",
    "        \"\"\"Function to get embeddings for POS words only\"\"\"\n",
    "        clean_text = text.replace('\\n', ' ')\n",
    "        words = clean_text.split()[:self.n_pos_words]\n",
    "        while len(words) < self.n_pos_words:\n",
    "            words.append(self.tokenizer.pad_token if self.tokenizer.pad_token else '[PAD]')\n",
    "        pos_text = ' '.join(words)\n",
    "        encoded = self.tokenizer(pos_text, return_tensors='pt', padding='max_length', truncation=True, max_length=self.n_pos_words + 2).to(self.device)\n",
    "        outputs = self.model(**encoded)\n",
    "        pos_emb = outputs.last_hidden_state.squeeze(0)[1:self.n_pos_words + 1, :]\n",
    "        return pos_emb.cpu()\n",
    "    \n",
    "    def _precompute_all(self):\n",
    "        \"\"\"Function to precompute embeddings for all samples\"\"\"\n",
    "        all_embeddings = []\n",
    "        all_pos_embeddings = []\n",
    "        with torch.no_grad():\n",
    "            for sample in tqdm(self.samples):\n",
    "                text = sample['text']\n",
    "                text_emb = self._get_text_embedding(text)\n",
    "                all_embeddings.append(text_emb)\n",
    "                pos_emb = self._get_pos_embedding(text)\n",
    "                all_pos_embeddings.append(pos_emb)\n",
    "        return all_embeddings, all_pos_embeddings\n",
    "    \n",
    "    def get_normalization_stats(self):\n",
    "        \"\"\"Function which returns normalization statistics for use during generation\"\"\"\n",
    "        return self.emb_mean, self.emb_std\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"Function to return length of samples in dataset\"\"\"\n",
    "        return len(self.embeddings)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Function to return requested items embeddings\"\"\"\n",
    "        return {'embeddings': self.embeddings[idx], 'pos_embeddings': self.pos_embeddings[idx]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcb89a2-2010-4780-b830-1e987cc9c36f",
   "metadata": {},
   "source": [
    "* Now that we have written dataset class let's make it's instance and provide it to dataloader which will divide given dataset into batches and shuffle it as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab23d643-5859-4b0a-88d0-6537e990d234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading BERT model: bert-base-uncased\n",
      "Hidden dimension: 768\n",
      "Pre-computing embeddings for 3274 samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3274/3274 [00:24<00:00, 131.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating normalization statistics.\n",
      "Raw embedding stats: mean=-0.0089, std=0.4152\n",
      "  Normalized stats: mean=-0.0000, std=1.0000\n",
      "Done! Dataset ready.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_name = 'bert-base-uncased'\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_pos_words = 3\n",
    "max_length = 64\n",
    "batch_size = 32\n",
    "\n",
    "dataset = ShakespeareDiffusionDataset(samples=all_data_samples, model_name=model_name, max_length=max_length, n_pos_words=n_pos_words, device=device)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf4cbe4-a6d8-4ea2-9a1f-2a9cf02a280b",
   "metadata": {},
   "source": [
    "* Let's view the first sample embedding returned by dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d743b9d-8800-4ce2-9b84-9f3f89116a3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'embeddings': tensor([[ 0.2457,  0.7117,  0.1252,  ..., -0.3991, -0.1186,  0.8122],\n",
       "         [ 0.6243,  1.4963,  1.0853,  ..., -0.2058,  1.3613,  1.0909],\n",
       "         [ 1.5481, -0.8929,  2.1297,  ..., -1.5306, -0.7201, -1.4385],\n",
       "         ...,\n",
       "         [ 0.5821, -0.1412,  0.7124,  ..., -0.1153,  0.6964, -0.6126],\n",
       "         [ 0.3272, -0.1976,  0.7915,  ..., -0.0949,  0.6067, -0.5615],\n",
       "         [-0.9759, -1.0914, -0.3940,  ...,  0.3828,  0.5988, -0.0785]]),\n",
       " 'pos_embeddings': tensor([[ 0.1607, -0.6030,  0.1060,  ..., -0.1467,  0.6751,  0.4106],\n",
       "         [ 0.2393, -0.7291,  1.0812,  ..., -0.6851,  0.1290, -0.3506],\n",
       "         [-0.7258, -0.9580, -0.3143,  ...,  0.1221,  1.0462, -0.0555]])}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44855c05-508d-4570-bc41-d4b6f53f2bef",
   "metadata": {},
   "source": [
    "* Now that we have our dataset ready let's create our Unet model\n",
    "* Before writing unet let's write utility networks required by Unet\n",
    "* So let's first write class for performing timestep embedding in Unet (Using professor's code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c427d71-2d6f-4128-930c-d5a49f78b5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinusoidalPositionEmbeddings(nn.Module):\n",
    "    \"\"\"Time step embeddings for diffusion\"\"\"\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, time):\n",
    "        device = time.device\n",
    "        half_dim = self.dim // 2\n",
    "        embeddings = math.log(10000) / (half_dim - 1)\n",
    "        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)\n",
    "        embeddings = time[:, None] * embeddings[None, :]\n",
    "        embeddings = torch.cat((embeddings.sin(), embeddings.cos()), dim=-1)\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f84385-3f6f-4f8c-aa3d-d0e4ac7d11da",
   "metadata": {},
   "source": [
    "* Now let's write dilated convolution block (Using professor's code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aae945d1-65ec-4f32-a4c5-8339b3fc4ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DilatedConvBlock(nn.Module):\n",
    "    \"\"\"Dilated convolution block with POS cross-attention conditioning\"\"\"\n",
    "    def __init__(self, channels, dilation, time_emb_dim, pos_dim, num_heads=4, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Dilated convolution for local text patterns\n",
    "        self.conv1 = nn.Conv1d(\n",
    "            channels, channels,\n",
    "            kernel_size=3,\n",
    "            dilation=dilation,\n",
    "            padding=dilation\n",
    "        )\n",
    "        self.conv2 = nn.Conv1d(\n",
    "            channels, channels,\n",
    "            kernel_size=3,\n",
    "            dilation=dilation,\n",
    "            padding=dilation\n",
    "        )\n",
    "        \n",
    "        # Time embedding projection\n",
    "        self.time_mlp = nn.Sequential(\n",
    "            nn.Linear(time_emb_dim, channels),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(channels, channels)\n",
    "        )\n",
    "\n",
    "        # Project POS embedding to match this layer's channel dimension\n",
    "        self.pos_proj = nn.Linear(pos_dim, channels)\n",
    "        \n",
    "        # Cross-attention to POS embeddings\n",
    "        # print(\"MHA channels:\", channels)\n",
    "        # print(\"MHA num_heads:\", num_heads)\n",
    "        self.pos_cross_attn = nn.MultiheadAttention(\n",
    "            channels,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Normalization layers\n",
    "        self.norm1 = nn.GroupNorm(8, channels)\n",
    "        self.norm2 = nn.GroupNorm(8, channels)\n",
    "        self.norm3 = nn.LayerNorm(channels)\n",
    "        \n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Activation\n",
    "        self.act = nn.SiLU()\n",
    "        \n",
    "    def forward(self, x, time_emb, pos_embedding):\n",
    "        \"\"\"\n",
    "        x: [batch, channels, seq_len]\n",
    "        time_emb: [batch, time_emb_dim]\n",
    "        pos_embedding: [batch, 3, channels] - Subject, Verb, Object embeddings\n",
    "        \"\"\"\n",
    "        residual = x\n",
    "        \n",
    "        # First conv block\n",
    "        x = self.norm1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.conv1(x)\n",
    "        \n",
    "        # Add time embedding\n",
    "        time_emb = self.time_mlp(time_emb)\n",
    "        x = x + time_emb[:, :, None]  # Broadcast across sequence\n",
    "        \n",
    "        # Second conv block\n",
    "        x = self.norm2(x)\n",
    "        x = self.act(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv2(x)\n",
    "        \n",
    "        # Add residual\n",
    "        x = x + residual\n",
    "\n",
    "        # Project POS to match current channel dimension\n",
    "        pos_projected = self.pos_proj(pos_embedding)  # [batch, 3, channels]\n",
    "        \n",
    "        # Cross-attention to POS (work in [batch, seq_len, channels] format)\n",
    "        x_transposed = x.transpose(1, 2)  # [batch, seq_len, channels]\n",
    "        x_transposed = self.norm3(x_transposed)\n",
    "\n",
    "        # print(\"x_transposed shape:\", x_transposed.shape)\n",
    "        # print(\"pos_embedding shape:\", pos_embedding.shape)\n",
    "        x_pos, _ = self.pos_cross_attn(\n",
    "            query=x_transposed,      # Text attends to...\n",
    "            key=pos_projected,       # POS embeddings\n",
    "            value=pos_projected\n",
    "        )\n",
    "        \n",
    "        x_transposed = x_transposed + x_pos\n",
    "        x = x_transposed.transpose(1, 2)  # Back to [batch, channels, seq_len]\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5b22e2-c3d5-4799-84d1-602d952ba786",
   "metadata": {},
   "source": [
    "* Now let's write down block code (Using professor's code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b9bb733-5adc-4ddd-a2af-c51026bdbbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownBlock(nn.Module):\n",
    "    \"\"\"Downsampling block\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, dilation, time_emb_dim, pos_dim, num_heads=4):\n",
    "        super().__init__()\n",
    "        self.conv_block = DilatedConvBlock(in_channels, dilation, time_emb_dim, pos_dim, num_heads)\n",
    "        self.downsample = nn.Conv1d(in_channels, out_channels, kernel_size=4, stride=2, padding=1)\n",
    "        \n",
    "    def forward(self, x, time_emb, pos_embedding):\n",
    "        x = self.conv_block(x, time_emb, pos_embedding)\n",
    "        skip = x\n",
    "        x = self.downsample(x)\n",
    "        return x, skip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768f883c-a694-4224-b071-c823d8f6e318",
   "metadata": {},
   "source": [
    "* Now let's write code for up block (using professor's code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a9038a9-0660-4572-91cf-4c5eef88bcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpBlock(nn.Module):\n",
    "    \"\"\"Upsampling block with skip connections\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, dilation, time_emb_dim, pos_dim, num_heads=4):\n",
    "        super().__init__()\n",
    "        self.upsample = nn.ConvTranspose1d(in_channels, out_channels, kernel_size=4, stride=2, padding=1)\n",
    "        # After concatenating with skip, we have out_channels * 2\n",
    "        self.conv_block = DilatedConvBlock(out_channels * 2, dilation, time_emb_dim, pos_dim, num_heads)\n",
    "        self.out_conv = nn.Conv1d(out_channels * 2, out_channels, kernel_size=1)\n",
    "        \n",
    "    def forward(self, x, skip, time_emb, pos_embedding):\n",
    "        x = self.upsample(x)\n",
    "        \n",
    "        # Handle size mismatch between upsampled x and skip connection\n",
    "        # This can happen due to odd-sized sequences and stride=2 operations\n",
    "        if x.shape[2] != skip.shape[2]:\n",
    "            # Crop or pad to match skip connection size\n",
    "            if x.shape[2] < skip.shape[2]:\n",
    "                # Pad x to match skip\n",
    "                diff = skip.shape[2] - x.shape[2]\n",
    "                x = F.pad(x, (0, diff))\n",
    "            else:\n",
    "                # Crop x to match skip\n",
    "                x = x[:, :, :skip.shape[2]]\n",
    "        \n",
    "        # Concatenate skip connection\n",
    "        x = torch.cat([x, skip], dim=1)\n",
    "        x = self.conv_block(x, time_emb, pos_embedding)\n",
    "        x = self.out_conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fefdb47-96e8-4655-a742-6348340ae97f",
   "metadata": {},
   "source": [
    "* Now we have all the utility classes for creating our Unet so let's create TextDiffusionUnet (Using professor's code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "40de42f6-4454-4d32-b25e-427fbaa8af7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDiffusionUNet(nn.Module):\n",
    "    \"\"\"\n",
    "    1D U-Net for text diffusion with POS conditioning\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        hidden_dim=768,          # BERT hidden dimension\n",
    "        time_emb_dim=256,        # Time embedding dimension\n",
    "        channels=[768, 512, 256, 128],  # Channel progression through U-Net\n",
    "        dilations=[1, 2, 4, 8],  # Dilation rates for each level\n",
    "        num_heads=8,             # Number of attention heads\n",
    "        dropout=0.1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        assert len(channels) == len(dilations), \"channels and dilations must have same length\"\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.time_emb_dim = time_emb_dim\n",
    "        \n",
    "        # Time embedding\n",
    "        self.time_mlp = nn.Sequential(\n",
    "            SinusoidalPositionEmbeddings(time_emb_dim),\n",
    "            nn.Linear(time_emb_dim, time_emb_dim * 4),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(time_emb_dim * 4, time_emb_dim)\n",
    "        )\n",
    "        \n",
    "        # Initial projection\n",
    "        self.input_proj = nn.Conv1d(hidden_dim, channels[0], kernel_size=1)\n",
    "        \n",
    "        # Encoder (downsampling path)\n",
    "        self.down_blocks = nn.ModuleList()\n",
    "        for i in range(len(channels) - 1):\n",
    "            self.down_blocks.append(\n",
    "                DownBlock(\n",
    "                    channels[i],\n",
    "                    channels[i + 1],\n",
    "                    dilations[i],\n",
    "                    time_emb_dim,\n",
    "                    hidden_dim,  # POS dimension\n",
    "                    num_heads\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        # Bottleneck\n",
    "        self.bottleneck = DilatedConvBlock(\n",
    "            channels[-1],\n",
    "            dilations[-1] * 2,  # Larger dilation at bottleneck\n",
    "            time_emb_dim,\n",
    "            hidden_dim,  # POS dimension\n",
    "            num_heads,\n",
    "            dropout\n",
    "        )\n",
    "        \n",
    "        # Decoder (upsampling path)\n",
    "        self.up_blocks = nn.ModuleList()\n",
    "        for i in range(len(channels) - 1, 0, -1):\n",
    "            self.up_blocks.append(\n",
    "                UpBlock(\n",
    "                    channels[i],\n",
    "                    channels[i - 1],\n",
    "                    dilations[i - 1],\n",
    "                    time_emb_dim,\n",
    "                    hidden_dim,  # POS dimension\n",
    "                    num_heads\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        # Final output projection\n",
    "        self.output_proj = nn.Sequential(\n",
    "            nn.GroupNorm(8, channels[0]),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv1d(channels[0], hidden_dim, kernel_size=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, timesteps, pos_embedding):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: [batch_size, seq_len, hidden_dim] - Noisy text embeddings\n",
    "            timesteps: [batch_size] - Diffusion timesteps\n",
    "            pos_embedding: [batch_size, 3, hidden_dim] - Subject, Verb, Object embeddings\n",
    "            \n",
    "        Returns:\n",
    "            [batch_size, seq_len, hidden_dim] - Predicted noise\n",
    "        \"\"\"\n",
    "        # Get time embeddings\n",
    "        time_emb = self.time_mlp(timesteps)\n",
    "        \n",
    "        # Convert to [batch, channels, seq_len] for conv operations\n",
    "        x = x.transpose(1, 2)  # [batch, hidden_dim, seq_len]\n",
    "        \n",
    "        # Initial projection\n",
    "        x = self.input_proj(x)  # [batch, channels[0], seq_len]\n",
    "        \n",
    "        # Encoder with skip connections\n",
    "        skips = []\n",
    "        for down_block in self.down_blocks:\n",
    "            x, skip = down_block(x, time_emb, pos_embedding)\n",
    "            skips.append(skip)\n",
    "            # print(\"Encoder: appending to skips block:\", skip.shape)\n",
    "        \n",
    "        # Bottleneck\n",
    "        x = self.bottleneck(x, time_emb, pos_embedding)\n",
    "        \n",
    "        # Decoder with skip connections\n",
    "        for up_block in self.up_blocks:\n",
    "            skip = skips.pop()\n",
    "            # print(\"Decoder: popping from skips block:\", skip.shape)\n",
    "            x = up_block(x, skip, time_emb, pos_embedding)\n",
    "        \n",
    "        # Final projection\n",
    "        x = self.output_proj(x)\n",
    "        \n",
    "        # Convert back to [batch, seq_len, hidden_dim]\n",
    "        x = x.transpose(1, 2)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2af1f5b-6849-40c1-a09a-dd4ef1353188",
   "metadata": {},
   "source": [
    "* Now let's write a function to create noise schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e45660d-4f20-48a9-b50b-5719d0c5614b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_noise_schedule(timesteps, beta1, beta2, device):\n",
    "    \"\"\"Function to create the noise schedule for diffusion\"\"\"\n",
    "    b_t = (beta2 - beta1) * torch.linspace(0, 1, timesteps + 1, device=device) + beta1\n",
    "    a_t = 1 - b_t\n",
    "    ab_t = torch.cumsum(a_t.log(), dim=0).exp()\n",
    "    ab_t[0] = 1\n",
    "    return b_t, a_t, ab_t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24195528-d0bd-499c-b90a-3b5de3d513a1",
   "metadata": {},
   "source": [
    "* Let's now create a noise schedule with 1000 time steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3929caf7-715e-47e2-847c-8064d0f798da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise schedule created:\n",
      "  ab_t[0] = 1.0000 (start: ~100% signal)\n",
      "  ab_t[500] = 0.0751 (middle)\n",
      "  ab_t[1000] = 0.0000 (end: ~0% signal)\n"
     ]
    }
   ],
   "source": [
    "timesteps = 1000\n",
    "beta1 = 2e-4\n",
    "beta2 = 0.02\n",
    "\n",
    "# Creating noise schedule\n",
    "b_t, a_t, ab_t = create_noise_schedule(timesteps, beta1, beta2, device)\n",
    "\n",
    "print(f\"Noise schedule created:\")\n",
    "print(f\"  ab_t[0] = {ab_t[0]:.4f} (start: ~100% signal)\")\n",
    "print(f\"  ab_t[{timesteps//2}] = {ab_t[timesteps//2]:.4f} (middle)\")\n",
    "print(f\"  ab_t[{timesteps}] = {ab_t[timesteps]:.4f} (end: ~0% signal)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9447bed0-d001-49bf-8b2d-83b886713889",
   "metadata": {},
   "source": [
    "* Now let's write a function that adds noise to clean embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "44900844-fea5-40e7-bc3f-54ce18b36809",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perturb_input(x, t, noise, ab_t):\n",
    "    \"\"\"Function for performing forward diffusion: Add noise to clean embeddings\"\"\"\n",
    "    ab_t_vals = ab_t[t][:, None, None]  # [batch, 1, 1]\n",
    "    return torch.sqrt(ab_t_vals) * x + torch.sqrt(1 - ab_t_vals) * noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef43abd-6c01-472b-8318-8dd39a3df2d9",
   "metadata": {},
   "source": [
    "* Now let's write a function to remove predicted noise and add a small noise back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "957bacb8-5fa4-42c6-af43-b37ad61bc66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def denoise_add_noise(x, t, pred_noise, a_t, b_t, ab_t, z=None):\n",
    "    \"\"\"Function to perform reverse diffusion: Remove predicted noise (and add small noise back)\"\"\"\n",
    "    if z is None:\n",
    "        z = torch.randn_like(x)\n",
    "    alpha_t = a_t[t]\n",
    "    beta_t = b_t[t]\n",
    "    alpha_bar_t = ab_t[t]\n",
    "    noise_coeff = (1 - alpha_t) / torch.sqrt(1 - alpha_bar_t)\n",
    "    mean = (x - noise_coeff * pred_noise) / torch.sqrt(alpha_t)\n",
    "    noise = torch.sqrt(beta_t) * z\n",
    "    return mean + noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e60a3a9-63fd-4b09-a0b0-534efbb7bc47",
   "metadata": {},
   "source": [
    "* Now let's create instance of a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ae359ec4-83c7-4722-a36e-f074e7639e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters: 63,567,360\n"
     ]
    }
   ],
   "source": [
    "hidden_dim = 768\n",
    "time_emb_dim = 256\n",
    "\n",
    "model = TextDiffusionUNet(hidden_dim=hidden_dim, time_emb_dim=time_emb_dim, channels=[768, 512, 256, 128], dilations=[1, 2, 4, 8], num_heads=8, dropout=0.1).to(device)\n",
    "\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Model parameters: {num_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2617cff2-a2be-4c91-9611-8d988ce3a92e",
   "metadata": {},
   "source": [
    "* Let's write a function to train diffusion model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bafee3ee-3be3-499f-9066-f559c610b5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_diffusion_model(model, dataloader, optimizer, timesteps, a_t, b_t, ab_t, n_epoch, device, save_dir='./weights/', context_mask_prob=0.1, emb_mean=0.0, emb_std=1.0):\n",
    "    \"\"\"Training function for diffusion model\"\"\"\n",
    "    model.train()\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    # Saving normalization stats\n",
    "    torch.save({'emb_mean': emb_mean, 'emb_std': emb_std}, os.path.join(save_dir, 'norm_stats.pth'))\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"TRAINING START (FIXED)\")\n",
    "    print(f\"Normalization: mean={emb_mean:.4f}, std={emb_std:.4f}\")\n",
    "    print(\"=\" * 60)\n",
    "    best_loss = float('inf')\n",
    "    for epoch in range(n_epoch):\n",
    "        model.train()\n",
    "        # Learning rate with warmup and decay\n",
    "        if epoch < 5:\n",
    "            # Warmup\n",
    "            lr = lrate * (epoch + 1) / 5\n",
    "        else:\n",
    "            # Cosine decay\n",
    "            lr = lrate * 0.5 * (1 + math.cos(math.pi * (epoch - 5) / (n_epoch - 5)))\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "        epoch_loss = 0\n",
    "        epoch_mse = 0\n",
    "        epoch_cos = 0\n",
    "        num_batches = 0\n",
    "        pbar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{n_epoch}\")\n",
    "        for batch in pbar:\n",
    "            optimizer.zero_grad()\n",
    "            x = batch['embeddings'].to(device)\n",
    "            pos_emb = batch['pos_embeddings'].to(device)\n",
    "            batch_size_actual = x.shape[0]\n",
    "            # Context masking (classifier-free guidance)\n",
    "            context_mask = torch.bernoulli(torch.zeros(batch_size_actual, device=device) + (1 - context_mask_prob))[:, None, None]\n",
    "            pos_emb_masked = pos_emb * context_mask\n",
    "            # Sampling noise\n",
    "            noise = torch.randn_like(x)\n",
    "            # Sampling timesteps\n",
    "            t = torch.randint(1, timesteps + 1, (batch_size_actual,), device=device)\n",
    "            # Forward diffusion\n",
    "            x_noisy = perturb_input(x, t, noise, ab_t)\n",
    "            # Predict noise\n",
    "            t_normalized = t.float() / timesteps\n",
    "            pred_noise = model(x_noisy, t_normalized, pos_emb_masked)\n",
    "            # MSE loss\n",
    "            mse_loss = F.mse_loss(pred_noise, noise)\n",
    "            # Cosine loss\n",
    "            pred_flat = pred_noise.reshape(-1, pred_noise.shape[-1])\n",
    "            noise_flat = noise.reshape(-1, noise.shape[-1])\n",
    "            cos_sim = F.cosine_similarity(pred_flat, noise_flat, dim=-1)\n",
    "            cos_loss = (1 - cos_sim).mean()\n",
    "            # Combined loss\n",
    "            loss = mse_loss + 0.1 * cos_loss\n",
    "            loss.backward()\n",
    "            # Gradient clipping\n",
    "            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_mse += mse_loss.item()\n",
    "            epoch_cos += cos_loss.item()\n",
    "            num_batches += 1\n",
    "            pbar.set_postfix({'loss': f'{loss.item():.4f}', 'mse': f'{mse_loss.item():.4f}', 'cos': f'{cos_loss.item():.4f}'})\n",
    "        # Epoch statistics\n",
    "        avg_loss = epoch_loss / num_batches\n",
    "        avg_mse = epoch_mse / num_batches\n",
    "        avg_cos = epoch_cos / num_batches\n",
    "        print(f\"Epoch {epoch+1}: Loss={avg_loss:.4f}, MSE={avg_mse:.4f}, \"\n",
    "              f\"CosLoss={avg_cos:.4f}, LR={lr:.6f}\")\n",
    "        # Saving best model\n",
    "        if avg_loss < best_loss:\n",
    "            best_loss = avg_loss\n",
    "            save_path = os.path.join(save_dir, \"text_diffusion_best.pth\")\n",
    "            torch.save({\n",
    "                'epoch': epoch + 1,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': avg_loss,\n",
    "                'emb_mean': emb_mean,\n",
    "                'emb_std': emb_std,\n",
    "            }, save_path)\n",
    "            print(f\"  New best model saved!\")\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(f\"TRAINING COMPLETE! Best loss: {best_loss:.4f}\")\n",
    "    print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a8e9f1-d5d3-48de-ba43-f92ca00ba213",
   "metadata": {},
   "source": [
    "* Now that we have writrten training function let's train our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2188e312-02fd-4024-b4b3-c99135276324",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch = 300\n",
    "save_dir = './weights/'\n",
    "lrate = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d72dec11-1f60-42fa-8d1d-22291cdf032a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TRAINING START (FIXED)\n",
      "Normalization: mean=0.0000, std=1.0000\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/300: 100%|| 102/102 [00:03<00:00, 28.40it/s, loss=1.0789, mse=0.9892, cos=0.8977]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss=1.1031, MSE=1.0081, CosLoss=0.9493, LR=0.000020\n",
      "  New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/300: 100%|| 102/102 [00:03<00:00, 31.16it/s, loss=0.9187, mse=0.8575, cos=0.6116]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Loss=1.0002, MSE=0.9261, CosLoss=0.7406, LR=0.000040\n",
      "  New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/300: 100%|| 102/102 [00:03<00:00, 32.03it/s, loss=0.8100, mse=0.7603, cos=0.4968]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Loss=0.8501, MSE=0.7966, CosLoss=0.5349, LR=0.000060\n",
      "  New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/300: 100%|| 102/102 [00:03<00:00, 32.11it/s, loss=0.6992, mse=0.6602, cos=0.3896]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Loss=0.7413, MSE=0.6987, CosLoss=0.4262, LR=0.000080\n",
      "  New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/300: 100%|| 102/102 [00:03<00:00, 31.72it/s, loss=0.6146, mse=0.5820, cos=0.3264]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Loss=0.6544, MSE=0.6188, CosLoss=0.3560, LR=0.000100\n",
      "  New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/300: 100%|| 102/102 [00:03<00:00, 31.45it/s, loss=0.5765, mse=0.5452, cos=0.3128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Loss=0.5942, MSE=0.5623, CosLoss=0.3183, LR=0.000100\n",
      "  New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/300: 100%|| 102/102 [00:03<00:00, 32.27it/s, loss=0.4995, mse=0.4738, cos=0.2570]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Loss=0.5471, MSE=0.5178, CosLoss=0.2926, LR=0.000100\n",
      "  New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/300: 100%|| 102/102 [00:03<00:00, 32.30it/s, loss=0.5096, mse=0.4813, cos=0.2824]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Loss=0.5094, MSE=0.4820, CosLoss=0.2737, LR=0.000100\n",
      "  New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/300: 100%|| 102/102 [00:03<00:00, 31.86it/s, loss=0.4327, mse=0.4100, cos=0.2261]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Loss=0.4731, MSE=0.4477, CosLoss=0.2545, LR=0.000100\n",
      "  New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/300: 100%|| 102/102 [00:03<00:00, 31.64it/s, loss=0.4351, mse=0.4111, cos=0.2397]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Loss=0.4464, MSE=0.4222, CosLoss=0.2417, LR=0.000100\n",
      "  New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/300: 100%|| 102/102 [00:03<00:00, 31.87it/s, loss=0.4534, mse=0.4280, cos=0.2531]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Loss=0.4270, MSE=0.4038, CosLoss=0.2328, LR=0.000100\n",
      "  New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/300: 100%|| 102/102 [00:03<00:00, 32.32it/s, loss=0.3710, mse=0.3513, cos=0.1971]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Loss=0.4120, MSE=0.3894, CosLoss=0.2259, LR=0.000100\n",
      "  New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/300: 100%|| 102/102 [00:03<00:00, 32.02it/s, loss=0.3598, mse=0.3405, cos=0.1932]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Loss=0.3928, MSE=0.3714, CosLoss=0.2139, LR=0.000100\n",
      "  New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/300: 100%|| 102/102 [00:03<00:00, 32.21it/s, loss=0.3867, mse=0.3659, cos=0.2080]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Loss=0.3810, MSE=0.3602, CosLoss=0.2081, LR=0.000100\n",
      "  New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/300: 100%|| 102/102 [00:03<00:00, 31.61it/s, loss=0.3541, mse=0.3349, cos=0.1917]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Loss=0.3694, MSE=0.3492, CosLoss=0.2024, LR=0.000100\n",
      "  New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/300: 100%|| 102/102 [00:03<00:00, 31.49it/s, loss=0.3779, mse=0.3567, cos=0.2127]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Loss=0.3596, MSE=0.3398, CosLoss=0.1976, LR=0.000100\n",
      "  New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/300: 100%|| 102/102 [00:03<00:00, 31.96it/s, loss=0.3515, mse=0.3324, cos=0.1906]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Loss=0.3509, MSE=0.3316, CosLoss=0.1930, LR=0.000100\n",
      "  New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/300: 100%|| 102/102 [00:03<00:00, 32.55it/s, loss=0.2960, mse=0.2808, cos=0.1524]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Loss=0.3387, MSE=0.3201, CosLoss=0.1856, LR=0.000100\n",
      "  New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/300: 100%|| 102/102 [00:03<00:00, 32.56it/s, loss=0.3139, mse=0.2973, cos=0.1670]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Loss=0.3257, MSE=0.3080, CosLoss=0.1777, LR=0.000100\n",
      "  New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/300: 100%|| 102/102 [00:03<00:00, 32.38it/s, loss=0.3323, mse=0.3133, cos=0.1901]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Loss=0.3182, MSE=0.3008, CosLoss=0.1742, LR=0.000099\n",
      "  New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/300: 100%|| 102/102 [00:03<00:00, 32.06it/s, loss=0.3275, mse=0.3084, cos=0.1907]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: Loss=0.3065, MSE=0.2898, CosLoss=0.1670, LR=0.000099\n",
      "  New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/300: 100%|| 102/102 [00:03<00:00, 32.12it/s, loss=0.2788, mse=0.2644, cos=0.1445]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: Loss=0.3037, MSE=0.2870, CosLoss=0.1667, LR=0.000099\n",
      "  New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/300: 100%|| 102/102 [00:03<00:00, 32.02it/s, loss=0.2403, mse=0.2281, cos=0.1218]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: Loss=0.2935, MSE=0.2775, CosLoss=0.1601, LR=0.000099\n",
      "  New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/300: 100%|| 102/102 [00:03<00:00, 32.55it/s, loss=0.2181, mse=0.2071, cos=0.1099]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: Loss=0.2868, MSE=0.2710, CosLoss=0.1583, LR=0.000099\n",
      "  New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/300: 100%|| 102/102 [00:03<00:00, 32.53it/s, loss=0.3106, mse=0.2935, cos=0.1706]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: Loss=0.2806, MSE=0.2652, CosLoss=0.1538, LR=0.000099\n",
      "  New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/300: 100%|| 102/102 [00:03<00:00, 32.28it/s, loss=0.2385, mse=0.2258, cos=0.1267]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: Loss=0.2799, MSE=0.2644, CosLoss=0.1549, LR=0.000099\n",
      "  New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/300: 100%|| 102/102 [00:03<00:00, 32.03it/s, loss=0.2628, mse=0.2488, cos=0.1401]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: Loss=0.2679, MSE=0.2532, CosLoss=0.1471, LR=0.000099\n",
      "  New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/300: 100%|| 102/102 [00:03<00:00, 32.49it/s, loss=0.2239, mse=0.2122, cos=0.1161]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: Loss=0.2647, MSE=0.2502, CosLoss=0.1452, LR=0.000099\n",
      "  New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/300: 100%|| 102/102 [00:03<00:00, 31.89it/s, loss=0.2547, mse=0.2410, cos=0.1371]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: Loss=0.2640, MSE=0.2494, CosLoss=0.1464, LR=0.000099\n",
      "  New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/300: 100%|| 102/102 [00:03<00:00, 32.21it/s, loss=0.2603, mse=0.2455, cos=0.1477]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: Loss=0.2559, MSE=0.2419, CosLoss=0.1407, LR=0.000098\n",
      "  New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/300: 100%|| 102/102 [00:03<00:00, 31.68it/s, loss=0.2528, mse=0.2384, cos=0.1441]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: Loss=0.2570, MSE=0.2428, CosLoss=0.1422, LR=0.000098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/300: 100%|| 102/102 [00:03<00:00, 32.04it/s, loss=0.2339, mse=0.2215, cos=0.1238]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: Loss=0.2470, MSE=0.2334, CosLoss=0.1356, LR=0.000098\n",
      "  New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/300: 100%|| 102/102 [00:03<00:00, 32.13it/s, loss=0.2328, mse=0.2200, cos=0.1277]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: Loss=0.2535, MSE=0.2393, CosLoss=0.1422, LR=0.000098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/300: 100%|| 102/102 [00:03<00:00, 32.29it/s, loss=0.2176, mse=0.2061, cos=0.1151]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: Loss=0.2398, MSE=0.2266, CosLoss=0.1325, LR=0.000098\n",
      "  New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/300: 100%|| 102/102 [00:03<00:00, 32.51it/s, loss=0.2262, mse=0.2143, cos=0.1193]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35: Loss=0.2418, MSE=0.2284, CosLoss=0.1343, LR=0.000098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/300: 100%|| 102/102 [00:03<00:00, 32.61it/s, loss=0.2192, mse=0.2076, cos=0.1157]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: Loss=0.2388, MSE=0.2255, CosLoss=0.1332, LR=0.000097\n",
      "  New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/300: 100%|| 102/102 [00:03<00:00, 31.92it/s, loss=0.2058, mse=0.1953, cos=0.1051]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37: Loss=0.2302, MSE=0.2175, CosLoss=0.1270, LR=0.000097\n",
      "  New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/300: 100%|| 102/102 [00:03<00:00, 32.05it/s, loss=0.1973, mse=0.1871, cos=0.1019]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: Loss=0.2337, MSE=0.2206, CosLoss=0.1307, LR=0.000097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/300: 100%|| 102/102 [00:03<00:00, 32.28it/s, loss=0.2396, mse=0.2261, cos=0.1354]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: Loss=0.2280, MSE=0.2153, CosLoss=0.1263, LR=0.000097\n",
      "  New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/300: 100%|| 102/102 [00:03<00:00, 32.39it/s, loss=0.2460, mse=0.2320, cos=0.1402]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: Loss=0.2207, MSE=0.2085, CosLoss=0.1219, LR=0.000097\n",
      "  New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/300: 100%|| 102/102 [00:03<00:00, 32.19it/s, loss=0.1982, mse=0.1878, cos=0.1037]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41: Loss=0.2210, MSE=0.2087, CosLoss=0.1227, LR=0.000097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/300: 100%|| 102/102 [00:03<00:00, 31.81it/s, loss=0.2317, mse=0.2182, cos=0.1349]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42: Loss=0.2126, MSE=0.2008, CosLoss=0.1182, LR=0.000096\n",
      "  New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/300: 100%|| 102/102 [00:03<00:00, 32.10it/s, loss=0.2217, mse=0.2088, cos=0.1297]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43: Loss=0.2136, MSE=0.2017, CosLoss=0.1192, LR=0.000096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/300: 100%|| 102/102 [00:03<00:00, 31.92it/s, loss=0.2584, mse=0.2433, cos=0.1517]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44: Loss=0.2200, MSE=0.2077, CosLoss=0.1233, LR=0.000096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/300: 100%|| 102/102 [00:03<00:00, 32.14it/s, loss=0.2552, mse=0.2401, cos=0.1508]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45: Loss=0.2134, MSE=0.2015, CosLoss=0.1192, LR=0.000096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/300: 100%|| 102/102 [00:03<00:00, 32.18it/s, loss=0.2144, mse=0.2027, cos=0.1172]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46: Loss=0.2108, MSE=0.1990, CosLoss=0.1175, LR=0.000096\n",
      "  New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/300: 100%|| 102/102 [00:03<00:00, 32.25it/s, loss=0.2142, mse=0.2022, cos=0.1202]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47: Loss=0.2095, MSE=0.1978, CosLoss=0.1175, LR=0.000095\n",
      "  New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/300: 100%|| 102/102 [00:03<00:00, 32.54it/s, loss=0.1697, mse=0.1606, cos=0.0912]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48: Loss=0.2097, MSE=0.1978, CosLoss=0.1187, LR=0.000095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/300: 100%|| 102/102 [00:03<00:00, 32.68it/s, loss=0.2056, mse=0.1945, cos=0.1106]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: Loss=0.2097, MSE=0.1977, CosLoss=0.1192, LR=0.000095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/300: 100%|| 102/102 [00:03<00:00, 32.54it/s, loss=0.1810, mse=0.1711, cos=0.0984]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50: Loss=0.2035, MSE=0.1921, CosLoss=0.1138, LR=0.000095\n",
      "  New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51/300: 100%|| 102/102 [00:03<00:00, 32.60it/s, loss=0.1628, mse=0.1545, cos=0.0827]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51: Loss=0.2038, MSE=0.1923, CosLoss=0.1151, LR=0.000094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52/300: 100%|| 102/102 [00:03<00:00, 32.34it/s, loss=0.2085, mse=0.1971, cos=0.1136]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52: Loss=0.2028, MSE=0.1913, CosLoss=0.1143, LR=0.000094\n",
      "  New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53/300: 100%|| 102/102 [00:03<00:00, 32.54it/s, loss=0.1445, mse=0.1371, cos=0.0743]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53: Loss=0.1915, MSE=0.1808, CosLoss=0.1068, LR=0.000094\n",
      "  New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54/300: 100%|| 102/102 [00:03<00:00, 32.46it/s, loss=0.2653, mse=0.2497, cos=0.1562]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54: Loss=0.1959, MSE=0.1849, CosLoss=0.1102, LR=0.000094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55/300: 100%|| 102/102 [00:03<00:00, 32.57it/s, loss=0.2504, mse=0.2355, cos=0.1489]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55: Loss=0.1955, MSE=0.1845, CosLoss=0.1101, LR=0.000093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56/300: 100%|| 102/102 [00:03<00:00, 32.54it/s, loss=0.2180, mse=0.2048, cos=0.1320]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56: Loss=0.2002, MSE=0.1889, CosLoss=0.1137, LR=0.000093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57/300: 100%|| 102/102 [00:03<00:00, 32.52it/s, loss=0.2680, mse=0.2520, cos=0.1604]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57: Loss=0.1927, MSE=0.1818, CosLoss=0.1086, LR=0.000093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58/300: 100%|| 102/102 [00:03<00:00, 32.06it/s, loss=0.1286, mse=0.1221, cos=0.0653]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58: Loss=0.1830, MSE=0.1728, CosLoss=0.1023, LR=0.000093\n",
      "  New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59/300: 100%|| 102/102 [00:03<00:00, 31.64it/s, loss=0.1596, mse=0.1512, cos=0.0844]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: Loss=0.1887, MSE=0.1781, CosLoss=0.1057, LR=0.000092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60/300: 100%|| 102/102 [00:03<00:00, 32.05it/s, loss=0.1773, mse=0.1680, cos=0.0929]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60: Loss=0.1899, MSE=0.1792, CosLoss=0.1072, LR=0.000092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61/300: 100%|| 102/102 [00:03<00:00, 31.94it/s, loss=0.1632, mse=0.1540, cos=0.0921]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61: Loss=0.1877, MSE=0.1771, CosLoss=0.1055, LR=0.000092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62/300: 100%|| 102/102 [00:03<00:00, 31.86it/s, loss=0.1516, mse=0.1437, cos=0.0781]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62: Loss=0.1899, MSE=0.1791, CosLoss=0.1076, LR=0.000091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63/300: 100%|| 102/102 [00:03<00:00, 32.07it/s, loss=0.1437, mse=0.1359, cos=0.0773]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63: Loss=0.1809, MSE=0.1708, CosLoss=0.1013, LR=0.000091\n",
      "  New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64/300: 100%|| 102/102 [00:03<00:00, 31.98it/s, loss=0.2558, mse=0.2410, cos=0.1473]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64: Loss=0.1887, MSE=0.1781, CosLoss=0.1067, LR=0.000091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65/300: 100%|| 102/102 [00:03<00:00, 32.04it/s, loss=0.1979, mse=0.1858, cos=0.1211]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65: Loss=0.1851, MSE=0.1746, CosLoss=0.1049, LR=0.000090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 66/300: 100%|| 102/102 [00:03<00:00, 32.16it/s, loss=0.2019, mse=0.1897, cos=0.1217]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66: Loss=0.1822, MSE=0.1719, CosLoss=0.1030, LR=0.000090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67/300: 100%|| 102/102 [00:03<00:00, 32.13it/s, loss=0.1481, mse=0.1403, cos=0.0773]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67: Loss=0.1807, MSE=0.1705, CosLoss=0.1020, LR=0.000090\n",
      "  New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 68/300: 100%|| 102/102 [00:03<00:00, 31.96it/s, loss=0.1496, mse=0.1418, cos=0.0783]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68: Loss=0.1844, MSE=0.1739, CosLoss=0.1045, LR=0.000089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69/300: 100%|| 102/102 [00:03<00:00, 32.09it/s, loss=0.2351, mse=0.2218, cos=0.1330]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69: Loss=0.1853, MSE=0.1747, CosLoss=0.1058, LR=0.000089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/300: 100%|| 102/102 [00:03<00:00, 32.53it/s, loss=0.1442, mse=0.1363, cos=0.0791]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70: Loss=0.1805, MSE=0.1702, CosLoss=0.1030, LR=0.000089\n",
      "  New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 71/300: 100%|| 102/102 [00:03<00:00, 32.11it/s, loss=0.1215, mse=0.1153, cos=0.0620]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71: Loss=0.1878, MSE=0.1770, CosLoss=0.1076, LR=0.000088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 72/300: 100%|| 102/102 [00:03<00:00, 32.04it/s, loss=0.2016, mse=0.1900, cos=0.1167]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72: Loss=0.1784, MSE=0.1683, CosLoss=0.1008, LR=0.000088\n",
      "  New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 73/300: 100%|| 102/102 [00:03<00:00, 32.20it/s, loss=0.1852, mse=0.1749, cos=0.1030]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73: Loss=0.1793, MSE=0.1691, CosLoss=0.1011, LR=0.000088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 74/300: 100%|| 102/102 [00:03<00:00, 32.11it/s, loss=0.1275, mse=0.1211, cos=0.0644]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74: Loss=0.1734, MSE=0.1636, CosLoss=0.0984, LR=0.000087\n",
      "  New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 75/300: 100%|| 102/102 [00:03<00:00, 32.02it/s, loss=0.2293, mse=0.2157, cos=0.1366]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75: Loss=0.1825, MSE=0.1721, CosLoss=0.1039, LR=0.000087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 76/300: 100%|| 102/102 [00:03<00:00, 32.49it/s, loss=0.1700, mse=0.1602, cos=0.0983]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76: Loss=0.1740, MSE=0.1642, CosLoss=0.0982, LR=0.000087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 77/300: 100%|| 102/102 [00:03<00:00, 32.41it/s, loss=0.2409, mse=0.2259, cos=0.1504]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77: Loss=0.1760, MSE=0.1660, CosLoss=0.0998, LR=0.000086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 78/300: 100%|| 102/102 [00:03<00:00, 32.23it/s, loss=0.1517, mse=0.1429, cos=0.0876]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78: Loss=0.1714, MSE=0.1618, CosLoss=0.0969, LR=0.000086\n",
      "  New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79/300: 100%|| 102/102 [00:03<00:00, 31.83it/s, loss=0.2191, mse=0.2062, cos=0.1286]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79: Loss=0.1725, MSE=0.1628, CosLoss=0.0972, LR=0.000086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 80/300: 100%|| 102/102 [00:03<00:00, 32.15it/s, loss=0.1869, mse=0.1758, cos=0.1109]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80: Loss=0.1741, MSE=0.1642, CosLoss=0.0990, LR=0.000085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 81/300: 100%|| 102/102 [00:03<00:00, 32.07it/s, loss=0.1398, mse=0.1325, cos=0.0726]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81: Loss=0.1767, MSE=0.1667, CosLoss=0.1008, LR=0.000085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 82/300: 100%|| 102/102 [00:03<00:00, 32.08it/s, loss=0.2253, mse=0.2114, cos=0.1396]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82: Loss=0.1754, MSE=0.1654, CosLoss=0.0995, LR=0.000084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 83/300: 100%|| 102/102 [00:03<00:00, 32.17it/s, loss=0.1314, mse=0.1243, cos=0.0708]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83: Loss=0.1702, MSE=0.1606, CosLoss=0.0965, LR=0.000084\n",
      "  New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 84/300: 100%|| 102/102 [00:03<00:00, 32.63it/s, loss=0.1389, mse=0.1316, cos=0.0727]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84: Loss=0.1692, MSE=0.1597, CosLoss=0.0956, LR=0.000084\n",
      "  New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 85/300: 100%|| 102/102 [00:03<00:00, 32.56it/s, loss=0.1977, mse=0.1866, cos=0.1114]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85: Loss=0.1720, MSE=0.1622, CosLoss=0.0978, LR=0.000083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 86/300: 100%|| 102/102 [00:03<00:00, 32.71it/s, loss=0.1215, mse=0.1152, cos=0.0622]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86: Loss=0.1733, MSE=0.1634, CosLoss=0.0990, LR=0.000083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 87/300: 100%|| 102/102 [00:03<00:00, 32.37it/s, loss=0.1630, mse=0.1534, cos=0.0959]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87: Loss=0.1657, MSE=0.1564, CosLoss=0.0935, LR=0.000083\n",
      "  New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 88/300: 100%|| 102/102 [00:03<00:00, 32.30it/s, loss=0.1469, mse=0.1392, cos=0.0774]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88: Loss=0.1697, MSE=0.1600, CosLoss=0.0968, LR=0.000082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 89/300: 100%|| 102/102 [00:03<00:00, 32.03it/s, loss=0.1068, mse=0.1014, cos=0.0536]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89: Loss=0.1641, MSE=0.1549, CosLoss=0.0927, LR=0.000082\n",
      "  New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 90/300: 100%|| 102/102 [00:03<00:00, 32.52it/s, loss=0.1578, mse=0.1485, cos=0.0928]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90: Loss=0.1699, MSE=0.1601, CosLoss=0.0973, LR=0.000081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 91/300: 100%|| 102/102 [00:03<00:00, 32.12it/s, loss=0.2258, mse=0.2130, cos=0.1282]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91: Loss=0.1686, MSE=0.1591, CosLoss=0.0958, LR=0.000081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 92/300: 100%|| 102/102 [00:03<00:00, 32.02it/s, loss=0.1251, mse=0.1186, cos=0.0643]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92: Loss=0.1641, MSE=0.1548, CosLoss=0.0933, LR=0.000080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 93/300: 100%|| 102/102 [00:03<00:00, 32.04it/s, loss=0.2027, mse=0.1906, cos=0.1212]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93: Loss=0.1774, MSE=0.1672, CosLoss=0.1018, LR=0.000080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 94/300: 100%|| 102/102 [00:03<00:00, 32.52it/s, loss=0.2595, mse=0.2437, cos=0.1581]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94: Loss=0.1621, MSE=0.1529, CosLoss=0.0918, LR=0.000080\n",
      "  New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 95/300: 100%|| 102/102 [00:03<00:00, 31.94it/s, loss=0.1941, mse=0.1825, cos=0.1157]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95: Loss=0.1682, MSE=0.1586, CosLoss=0.0958, LR=0.000079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 96/300: 100%|| 102/102 [00:03<00:00, 32.02it/s, loss=0.1654, mse=0.1559, cos=0.0949]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96: Loss=0.1673, MSE=0.1578, CosLoss=0.0955, LR=0.000079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 97/300: 100%|| 102/102 [00:03<00:00, 32.16it/s, loss=0.1951, mse=0.1833, cos=0.1179]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97: Loss=0.1684, MSE=0.1588, CosLoss=0.0964, LR=0.000078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 98/300: 100%|| 102/102 [00:03<00:00, 32.14it/s, loss=0.1940, mse=0.1829, cos=0.1113]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98: Loss=0.1623, MSE=0.1531, CosLoss=0.0919, LR=0.000078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99/300: 100%|| 102/102 [00:03<00:00, 32.09it/s, loss=0.1441, mse=0.1359, cos=0.0820]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: Loss=0.1616, MSE=0.1524, CosLoss=0.0915, LR=0.000077\n",
      "  New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 100/300: 100%|| 102/102 [00:03<00:00, 32.09it/s, loss=0.1960, mse=0.1847, cos=0.1126]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100: Loss=0.1657, MSE=0.1562, CosLoss=0.0945, LR=0.000077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 101/300: 100%|| 102/102 [00:03<00:00, 32.04it/s, loss=0.1779, mse=0.1665, cos=0.1142]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101: Loss=0.1634, MSE=0.1541, CosLoss=0.0932, LR=0.000077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 102/300: 100%|| 102/102 [00:03<00:00, 32.11it/s, loss=0.1472, mse=0.1391, cos=0.0806]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102: Loss=0.1653, MSE=0.1559, CosLoss=0.0942, LR=0.000076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 103/300: 100%|| 102/102 [00:03<00:00, 32.01it/s, loss=0.1676, mse=0.1582, cos=0.0939]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 103: Loss=0.1665, MSE=0.1569, CosLoss=0.0961, LR=0.000076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 104/300: 100%|| 102/102 [00:03<00:00, 32.00it/s, loss=0.2166, mse=0.2042, cos=0.1240]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 104: Loss=0.1665, MSE=0.1571, CosLoss=0.0948, LR=0.000075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 105/300: 100%|| 102/102 [00:03<00:00, 32.19it/s, loss=0.2068, mse=0.1947, cos=0.1210]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105: Loss=0.1666, MSE=0.1571, CosLoss=0.0955, LR=0.000075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 106/300: 100%|| 102/102 [00:03<00:00, 32.54it/s, loss=0.1136, mse=0.1077, cos=0.0589]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106: Loss=0.1596, MSE=0.1506, CosLoss=0.0906, LR=0.000074\n",
      "  New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 107/300: 100%|| 102/102 [00:03<00:00, 32.03it/s, loss=0.1280, mse=0.1212, cos=0.0679]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107: Loss=0.1590, MSE=0.1499, CosLoss=0.0907, LR=0.000074\n",
      "  New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 108/300: 100%|| 102/102 [00:03<00:00, 32.08it/s, loss=0.1445, mse=0.1364, cos=0.0801]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108: Loss=0.1651, MSE=0.1557, CosLoss=0.0942, LR=0.000073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 109/300: 100%|| 102/102 [00:03<00:00, 32.18it/s, loss=0.1097, mse=0.1040, cos=0.0566]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109: Loss=0.1581, MSE=0.1491, CosLoss=0.0898, LR=0.000073\n",
      "  New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 110/300: 100%|| 102/102 [00:03<00:00, 31.44it/s, loss=0.2198, mse=0.2061, cos=0.1372]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110: Loss=0.1608, MSE=0.1515, CosLoss=0.0922, LR=0.000072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 111/300: 100%|| 102/102 [00:03<00:00, 32.01it/s, loss=0.1390, mse=0.1315, cos=0.0743]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111: Loss=0.1635, MSE=0.1541, CosLoss=0.0940, LR=0.000072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 112/300: 100%|| 102/102 [00:03<00:00, 32.10it/s, loss=0.1298, mse=0.1227, cos=0.0705]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112: Loss=0.1606, MSE=0.1514, CosLoss=0.0920, LR=0.000071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 113/300: 100%|| 102/102 [00:03<00:00, 32.30it/s, loss=0.1860, mse=0.1748, cos=0.1124]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113: Loss=0.1563, MSE=0.1475, CosLoss=0.0885, LR=0.000071\n",
      "  New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 114/300: 100%|| 102/102 [00:03<00:00, 31.99it/s, loss=0.1506, mse=0.1421, cos=0.0846]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114: Loss=0.1652, MSE=0.1557, CosLoss=0.0949, LR=0.000070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 115/300: 100%|| 102/102 [00:03<00:00, 32.18it/s, loss=0.1506, mse=0.1424, cos=0.0818]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115: Loss=0.1581, MSE=0.1491, CosLoss=0.0898, LR=0.000070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 116/300: 100%|| 102/102 [00:03<00:00, 32.55it/s, loss=0.1437, mse=0.1359, cos=0.0777]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116: Loss=0.1638, MSE=0.1544, CosLoss=0.0940, LR=0.000069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 117/300: 100%|| 102/102 [00:03<00:00, 32.74it/s, loss=0.1806, mse=0.1702, cos=0.1033]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117: Loss=0.1575, MSE=0.1485, CosLoss=0.0891, LR=0.000069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 118/300: 100%|| 102/102 [00:03<00:00, 32.25it/s, loss=0.1975, mse=0.1861, cos=0.1137]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118: Loss=0.1631, MSE=0.1538, CosLoss=0.0937, LR=0.000068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 119/300: 100%|| 102/102 [00:03<00:00, 32.49it/s, loss=0.1795, mse=0.1691, cos=0.1042]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119: Loss=0.1553, MSE=0.1464, CosLoss=0.0884, LR=0.000068\n",
      "  New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 120/300: 100%|| 102/102 [00:03<00:00, 32.28it/s, loss=0.1194, mse=0.1132, cos=0.0620]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120: Loss=0.1557, MSE=0.1468, CosLoss=0.0884, LR=0.000067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 121/300: 100%|| 102/102 [00:03<00:00, 32.04it/s, loss=0.1755, mse=0.1657, cos=0.0981]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121: Loss=0.1618, MSE=0.1526, CosLoss=0.0919, LR=0.000067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 122/300: 100%|| 102/102 [00:03<00:00, 32.19it/s, loss=0.2039, mse=0.1914, cos=0.1248]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122: Loss=0.1585, MSE=0.1495, CosLoss=0.0899, LR=0.000066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 123/300: 100%|| 102/102 [00:03<00:00, 32.08it/s, loss=0.1195, mse=0.1127, cos=0.0683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123: Loss=0.1594, MSE=0.1503, CosLoss=0.0915, LR=0.000066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 124/300: 100%|| 102/102 [00:03<00:00, 32.01it/s, loss=0.1316, mse=0.1241, cos=0.0751]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124: Loss=0.1539, MSE=0.1451, CosLoss=0.0879, LR=0.000065\n",
      "  New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 125/300: 100%|| 102/102 [00:03<00:00, 32.14it/s, loss=0.1596, mse=0.1503, cos=0.0921]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125: Loss=0.1590, MSE=0.1499, CosLoss=0.0907, LR=0.000065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 126/300: 100%|| 102/102 [00:03<00:00, 32.08it/s, loss=0.1328, mse=0.1252, cos=0.0757]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 126: Loss=0.1502, MSE=0.1417, CosLoss=0.0845, LR=0.000064\n",
      "  New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 127/300: 100%|| 102/102 [00:03<00:00, 31.82it/s, loss=0.1214, mse=0.1149, cos=0.0645]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 127: Loss=0.1572, MSE=0.1482, CosLoss=0.0900, LR=0.000064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 128/300: 100%|| 102/102 [00:03<00:00, 32.06it/s, loss=0.1612, mse=0.1518, cos=0.0942]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 128: Loss=0.1573, MSE=0.1484, CosLoss=0.0898, LR=0.000063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 129/300: 100%|| 102/102 [00:03<00:00, 32.09it/s, loss=0.1293, mse=0.1225, cos=0.0677]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 129: Loss=0.1588, MSE=0.1497, CosLoss=0.0910, LR=0.000063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 130/300: 100%|| 102/102 [00:03<00:00, 32.02it/s, loss=0.1259, mse=0.1189, cos=0.0696]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130: Loss=0.1534, MSE=0.1447, CosLoss=0.0872, LR=0.000062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 131/300: 100%|| 102/102 [00:03<00:00, 32.11it/s, loss=0.1288, mse=0.1215, cos=0.0725]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131: Loss=0.1542, MSE=0.1454, CosLoss=0.0881, LR=0.000062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 132/300: 100%|| 102/102 [00:03<00:00, 32.17it/s, loss=0.1839, mse=0.1728, cos=0.1115]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132: Loss=0.1630, MSE=0.1536, CosLoss=0.0937, LR=0.000061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 133/300: 100%|| 102/102 [00:03<00:00, 32.05it/s, loss=0.1100, mse=0.1039, cos=0.0617]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 133: Loss=0.1559, MSE=0.1470, CosLoss=0.0894, LR=0.000061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 134/300: 100%|| 102/102 [00:03<00:00, 32.15it/s, loss=0.1071, mse=0.1016, cos=0.0545]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134: Loss=0.1500, MSE=0.1415, CosLoss=0.0856, LR=0.000060\n",
      "  New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 135/300: 100%|| 102/102 [00:03<00:00, 31.99it/s, loss=0.0957, mse=0.0907, cos=0.0501]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135: Loss=0.1497, MSE=0.1412, CosLoss=0.0850, LR=0.000060\n",
      "  New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 136/300: 100%|| 102/102 [00:03<00:00, 32.63it/s, loss=0.1700, mse=0.1594, cos=0.1060]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 136: Loss=0.1498, MSE=0.1413, CosLoss=0.0853, LR=0.000059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 137/300: 100%|| 102/102 [00:03<00:00, 32.56it/s, loss=0.2153, mse=0.2025, cos=0.1273]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 137: Loss=0.1522, MSE=0.1435, CosLoss=0.0871, LR=0.000059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 138/300: 100%|| 102/102 [00:03<00:00, 32.18it/s, loss=0.1351, mse=0.1277, cos=0.0744]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 138: Loss=0.1543, MSE=0.1454, CosLoss=0.0887, LR=0.000058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 139/300: 100%|| 102/102 [00:03<00:00, 32.53it/s, loss=0.1582, mse=0.1490, cos=0.0912]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 139: Loss=0.1501, MSE=0.1415, CosLoss=0.0858, LR=0.000058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 140/300: 100%|| 102/102 [00:03<00:00, 32.31it/s, loss=0.1531, mse=0.1446, cos=0.0853]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 140: Loss=0.1581, MSE=0.1489, CosLoss=0.0914, LR=0.000057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 141/300: 100%|| 102/102 [00:03<00:00, 32.31it/s, loss=0.1344, mse=0.1265, cos=0.0796]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 141: Loss=0.1546, MSE=0.1457, CosLoss=0.0891, LR=0.000057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 142/300: 100%|| 102/102 [00:03<00:00, 32.32it/s, loss=0.1086, mse=0.1026, cos=0.0600]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142: Loss=0.1540, MSE=0.1451, CosLoss=0.0888, LR=0.000056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 143/300: 100%|| 102/102 [00:03<00:00, 32.20it/s, loss=0.1713, mse=0.1615, cos=0.0980]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143: Loss=0.1559, MSE=0.1470, CosLoss=0.0893, LR=0.000056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 144/300: 100%|| 102/102 [00:03<00:00, 32.06it/s, loss=0.1317, mse=0.1236, cos=0.0804]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 144: Loss=0.1535, MSE=0.1447, CosLoss=0.0882, LR=0.000055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 145/300: 100%|| 102/102 [00:03<00:00, 32.08it/s, loss=0.1912, mse=0.1804, cos=0.1082]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145: Loss=0.1489, MSE=0.1405, CosLoss=0.0844, LR=0.000055\n",
      "  New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 146/300: 100%|| 102/102 [00:03<00:00, 31.99it/s, loss=0.1290, mse=0.1222, cos=0.0684]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 146: Loss=0.1500, MSE=0.1414, CosLoss=0.0859, LR=0.000054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 147/300: 100%|| 102/102 [00:03<00:00, 32.08it/s, loss=0.1620, mse=0.1530, cos=0.0908]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147: Loss=0.1554, MSE=0.1464, CosLoss=0.0896, LR=0.000053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 148/300: 100%|| 102/102 [00:03<00:00, 32.48it/s, loss=0.1251, mse=0.1184, cos=0.0668]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 148: Loss=0.1503, MSE=0.1417, CosLoss=0.0862, LR=0.000053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 149/300: 100%|| 102/102 [00:03<00:00, 32.64it/s, loss=0.1544, mse=0.1459, cos=0.0855]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: Loss=0.1505, MSE=0.1420, CosLoss=0.0853, LR=0.000052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 150/300: 100%|| 102/102 [00:03<00:00, 32.23it/s, loss=0.1778, mse=0.1674, cos=0.1037]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150: Loss=0.1510, MSE=0.1424, CosLoss=0.0856, LR=0.000052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 151/300: 100%|| 102/102 [00:03<00:00, 32.32it/s, loss=0.1419, mse=0.1343, cos=0.0759]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151: Loss=0.1546, MSE=0.1457, CosLoss=0.0891, LR=0.000051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 152/300: 100%|| 102/102 [00:03<00:00, 32.18it/s, loss=0.1520, mse=0.1436, cos=0.0836]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 152: Loss=0.1471, MSE=0.1387, CosLoss=0.0837, LR=0.000051\n",
      "  New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 153/300: 100%|| 102/102 [00:03<00:00, 32.56it/s, loss=0.1643, mse=0.1549, cos=0.0941]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 153: Loss=0.1533, MSE=0.1444, CosLoss=0.0881, LR=0.000050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 154/300: 100%|| 102/102 [00:03<00:00, 32.66it/s, loss=0.1143, mse=0.1083, cos=0.0599]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 154: Loss=0.1511, MSE=0.1424, CosLoss=0.0867, LR=0.000050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 155/300: 100%|| 102/102 [00:03<00:00, 32.07it/s, loss=0.1390, mse=0.1306, cos=0.0844]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155: Loss=0.1485, MSE=0.1400, CosLoss=0.0851, LR=0.000049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 156/300: 100%|| 102/102 [00:03<00:00, 32.07it/s, loss=0.1980, mse=0.1864, cos=0.1155]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 156: Loss=0.1485, MSE=0.1400, CosLoss=0.0847, LR=0.000049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 157/300: 100%|| 102/102 [00:03<00:00, 31.97it/s, loss=0.1731, mse=0.1622, cos=0.1087]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 157: Loss=0.1480, MSE=0.1395, CosLoss=0.0844, LR=0.000048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 158/300: 100%|| 102/102 [00:03<00:00, 31.85it/s, loss=0.1396, mse=0.1321, cos=0.0753]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 158: Loss=0.1552, MSE=0.1462, CosLoss=0.0896, LR=0.000048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 159/300: 100%|| 102/102 [00:03<00:00, 31.87it/s, loss=0.1609, mse=0.1514, cos=0.0945]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 159: Loss=0.1446, MSE=0.1363, CosLoss=0.0820, LR=0.000047\n",
      "  New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 160/300: 100%|| 102/102 [00:03<00:00, 31.52it/s, loss=0.1453, mse=0.1373, cos=0.0792]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160: Loss=0.1446, MSE=0.1364, CosLoss=0.0817, LR=0.000047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 161/300: 100%|| 102/102 [00:03<00:00, 31.92it/s, loss=0.1010, mse=0.0957, cos=0.0534]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161: Loss=0.1461, MSE=0.1378, CosLoss=0.0833, LR=0.000046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 162/300: 100%|| 102/102 [00:03<00:00, 32.14it/s, loss=0.2122, mse=0.1998, cos=0.1241]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 162: Loss=0.1434, MSE=0.1352, CosLoss=0.0818, LR=0.000045\n",
      "  New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 163/300: 100%|| 102/102 [00:03<00:00, 32.20it/s, loss=0.1267, mse=0.1201, cos=0.0666]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 163: Loss=0.1437, MSE=0.1356, CosLoss=0.0817, LR=0.000045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 164/300: 100%|| 102/102 [00:03<00:00, 32.03it/s, loss=0.1061, mse=0.1004, cos=0.0564]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 164: Loss=0.1479, MSE=0.1394, CosLoss=0.0852, LR=0.000044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 165/300: 100%|| 102/102 [00:03<00:00, 32.10it/s, loss=0.1928, mse=0.1807, cos=0.1209]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 165: Loss=0.1507, MSE=0.1420, CosLoss=0.0870, LR=0.000044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 166/300: 100%|| 102/102 [00:03<00:00, 32.21it/s, loss=0.1070, mse=0.1015, cos=0.0547]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 166: Loss=0.1495, MSE=0.1410, CosLoss=0.0849, LR=0.000043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 167/300: 100%|| 102/102 [00:03<00:00, 32.15it/s, loss=0.1361, mse=0.1284, cos=0.0765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 167: Loss=0.1539, MSE=0.1450, CosLoss=0.0892, LR=0.000043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 168/300: 100%|| 102/102 [00:03<00:00, 32.15it/s, loss=0.2188, mse=0.2057, cos=0.1304]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 168: Loss=0.1510, MSE=0.1423, CosLoss=0.0867, LR=0.000042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 169/300: 100%|| 102/102 [00:03<00:00, 32.20it/s, loss=0.1844, mse=0.1732, cos=0.1117]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169: Loss=0.1488, MSE=0.1403, CosLoss=0.0851, LR=0.000042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 170/300: 100%|| 102/102 [00:03<00:00, 32.19it/s, loss=0.1500, mse=0.1411, cos=0.0885]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 170: Loss=0.1457, MSE=0.1374, CosLoss=0.0832, LR=0.000041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 171/300: 100%|| 102/102 [00:03<00:00, 32.19it/s, loss=0.1098, mse=0.1040, cos=0.0573]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 171: Loss=0.1479, MSE=0.1395, CosLoss=0.0840, LR=0.000041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 172/300: 100%|| 102/102 [00:03<00:00, 32.27it/s, loss=0.1917, mse=0.1805, cos=0.1120]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172: Loss=0.1453, MSE=0.1370, CosLoss=0.0830, LR=0.000040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 173/300: 100%|| 102/102 [00:03<00:00, 32.19it/s, loss=0.1933, mse=0.1813, cos=0.1199]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 173: Loss=0.1424, MSE=0.1343, CosLoss=0.0813, LR=0.000040\n",
      "  New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 174/300: 100%|| 102/102 [00:03<00:00, 31.95it/s, loss=0.1000, mse=0.0949, cos=0.0515]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 174: Loss=0.1513, MSE=0.1426, CosLoss=0.0873, LR=0.000039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 175/300: 100%|| 102/102 [00:03<00:00, 31.97it/s, loss=0.1537, mse=0.1447, cos=0.0901]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175: Loss=0.1473, MSE=0.1389, CosLoss=0.0846, LR=0.000039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 176/300: 100%|| 102/102 [00:03<00:00, 31.98it/s, loss=0.2474, mse=0.2324, cos=0.1504]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 176: Loss=0.1488, MSE=0.1403, CosLoss=0.0851, LR=0.000038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 177/300: 100%|| 102/102 [00:03<00:00, 31.86it/s, loss=0.1448, mse=0.1366, cos=0.0819]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 177: Loss=0.1523, MSE=0.1434, CosLoss=0.0882, LR=0.000038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 178/300: 100%|| 102/102 [00:03<00:00, 31.89it/s, loss=0.1774, mse=0.1663, cos=0.1106]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 178: Loss=0.1465, MSE=0.1381, CosLoss=0.0844, LR=0.000037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 179/300: 100%|| 102/102 [00:03<00:00, 32.15it/s, loss=0.1536, mse=0.1451, cos=0.0849]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179: Loss=0.1452, MSE=0.1369, CosLoss=0.0838, LR=0.000037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 180/300: 100%|| 102/102 [00:03<00:00, 32.27it/s, loss=0.1044, mse=0.0980, cos=0.0643]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180: Loss=0.1437, MSE=0.1355, CosLoss=0.0825, LR=0.000036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 181/300: 100%|| 102/102 [00:03<00:00, 32.13it/s, loss=0.1545, mse=0.1455, cos=0.0901]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181: Loss=0.1507, MSE=0.1421, CosLoss=0.0865, LR=0.000036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 182/300: 100%|| 102/102 [00:03<00:00, 32.15it/s, loss=0.1544, mse=0.1459, cos=0.0854]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 182: Loss=0.1362, MSE=0.1285, CosLoss=0.0773, LR=0.000035\n",
      "  New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 183/300: 100%|| 102/102 [00:03<00:00, 32.54it/s, loss=0.1472, mse=0.1390, cos=0.0820]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 183: Loss=0.1458, MSE=0.1374, CosLoss=0.0837, LR=0.000035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 184/300: 100%|| 102/102 [00:03<00:00, 32.49it/s, loss=0.0985, mse=0.0934, cos=0.0512]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 184: Loss=0.1390, MSE=0.1311, CosLoss=0.0792, LR=0.000034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 185/300: 100%|| 102/102 [00:03<00:00, 32.12it/s, loss=0.1505, mse=0.1419, cos=0.0866]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 185: Loss=0.1425, MSE=0.1344, CosLoss=0.0808, LR=0.000034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 186/300: 100%|| 102/102 [00:03<00:00, 32.17it/s, loss=0.1645, mse=0.1552, cos=0.0931]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 186: Loss=0.1429, MSE=0.1348, CosLoss=0.0813, LR=0.000033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 187/300: 100%|| 102/102 [00:03<00:00, 32.16it/s, loss=0.1265, mse=0.1193, cos=0.0721]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 187: Loss=0.1506, MSE=0.1420, CosLoss=0.0869, LR=0.000033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 188/300: 100%|| 102/102 [00:03<00:00, 32.23it/s, loss=0.1150, mse=0.1089, cos=0.0609]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 188: Loss=0.1417, MSE=0.1336, CosLoss=0.0814, LR=0.000032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 189/300: 100%|| 102/102 [00:03<00:00, 32.19it/s, loss=0.1049, mse=0.0985, cos=0.0634]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 189: Loss=0.1484, MSE=0.1398, CosLoss=0.0858, LR=0.000032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 190/300: 100%|| 102/102 [00:03<00:00, 32.13it/s, loss=0.1309, mse=0.1237, cos=0.0726]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 190: Loss=0.1463, MSE=0.1379, CosLoss=0.0839, LR=0.000031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 191/300: 100%|| 102/102 [00:03<00:00, 32.19it/s, loss=0.1737, mse=0.1634, cos=0.1035]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 191: Loss=0.1427, MSE=0.1345, CosLoss=0.0821, LR=0.000031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 192/300: 100%|| 102/102 [00:03<00:00, 32.25it/s, loss=0.1628, mse=0.1538, cos=0.0900]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 192: Loss=0.1377, MSE=0.1298, CosLoss=0.0787, LR=0.000030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 193/300: 100%|| 102/102 [00:03<00:00, 31.96it/s, loss=0.1708, mse=0.1611, cos=0.0974]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 193: Loss=0.1490, MSE=0.1404, CosLoss=0.0855, LR=0.000030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 194/300: 100%|| 102/102 [00:03<00:00, 31.88it/s, loss=0.0974, mse=0.0924, cos=0.0498]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 194: Loss=0.1431, MSE=0.1349, CosLoss=0.0817, LR=0.000029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 195/300: 100%|| 102/102 [00:03<00:00, 31.83it/s, loss=0.1153, mse=0.1088, cos=0.0646]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 195: Loss=0.1459, MSE=0.1376, CosLoss=0.0840, LR=0.000029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 196/300: 100%|| 102/102 [00:03<00:00, 31.85it/s, loss=0.1029, mse=0.0976, cos=0.0528]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 196: Loss=0.1448, MSE=0.1365, CosLoss=0.0828, LR=0.000028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 197/300: 100%|| 102/102 [00:03<00:00, 32.00it/s, loss=0.1628, mse=0.1533, cos=0.0942]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 197: Loss=0.1400, MSE=0.1321, CosLoss=0.0797, LR=0.000028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 198/300: 100%|| 102/102 [00:03<00:00, 31.98it/s, loss=0.1159, mse=0.1096, cos=0.0630]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 198: Loss=0.1446, MSE=0.1362, CosLoss=0.0838, LR=0.000027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 199/300: 100%|| 102/102 [00:03<00:00, 32.18it/s, loss=0.1404, mse=0.1325, cos=0.0787]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: Loss=0.1470, MSE=0.1385, CosLoss=0.0851, LR=0.000027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 200/300: 100%|| 102/102 [00:03<00:00, 32.03it/s, loss=0.1381, mse=0.1306, cos=0.0749]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200: Loss=0.1450, MSE=0.1367, CosLoss=0.0832, LR=0.000026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 201/300: 100%|| 102/102 [00:03<00:00, 32.18it/s, loss=0.1022, mse=0.0965, cos=0.0574]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 201: Loss=0.1429, MSE=0.1346, CosLoss=0.0822, LR=0.000026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 202/300: 100%|| 102/102 [00:03<00:00, 32.30it/s, loss=0.0999, mse=0.0946, cos=0.0524]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 202: Loss=0.1463, MSE=0.1379, CosLoss=0.0842, LR=0.000025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 203/300: 100%|| 102/102 [00:03<00:00, 32.30it/s, loss=0.0921, mse=0.0872, cos=0.0488]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 203: Loss=0.1408, MSE=0.1327, CosLoss=0.0807, LR=0.000025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 204/300: 100%|| 102/102 [00:03<00:00, 32.06it/s, loss=0.1209, mse=0.1142, cos=0.0678]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 204: Loss=0.1449, MSE=0.1366, CosLoss=0.0831, LR=0.000024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 205/300: 100%|| 102/102 [00:03<00:00, 31.98it/s, loss=0.1677, mse=0.1579, cos=0.0971]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 205: Loss=0.1427, MSE=0.1345, CosLoss=0.0817, LR=0.000024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 206/300: 100%|| 102/102 [00:03<00:00, 32.53it/s, loss=0.2121, mse=0.1980, cos=0.1408]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 206: Loss=0.1393, MSE=0.1313, CosLoss=0.0798, LR=0.000023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 207/300: 100%|| 102/102 [00:03<00:00, 32.57it/s, loss=0.1202, mse=0.1133, cos=0.0693]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 207: Loss=0.1463, MSE=0.1379, CosLoss=0.0840, LR=0.000023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 208/300: 100%|| 102/102 [00:03<00:00, 32.37it/s, loss=0.1408, mse=0.1332, cos=0.0759]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 208: Loss=0.1414, MSE=0.1334, CosLoss=0.0808, LR=0.000023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 209/300: 100%|| 102/102 [00:03<00:00, 32.18it/s, loss=0.0965, mse=0.0911, cos=0.0538]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 209: Loss=0.1442, MSE=0.1359, CosLoss=0.0831, LR=0.000022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 210/300: 100%|| 102/102 [00:03<00:00, 31.96it/s, loss=0.0846, mse=0.0802, cos=0.0431]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 210: Loss=0.1461, MSE=0.1378, CosLoss=0.0837, LR=0.000022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 211/300: 100%|| 102/102 [00:03<00:00, 31.90it/s, loss=0.1479, mse=0.1398, cos=0.0808]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 211: Loss=0.1406, MSE=0.1326, CosLoss=0.0799, LR=0.000021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 212/300: 100%|| 102/102 [00:03<00:00, 31.75it/s, loss=0.1313, mse=0.1240, cos=0.0738]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 212: Loss=0.1344, MSE=0.1268, CosLoss=0.0762, LR=0.000021\n",
      "  New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 213/300: 100%|| 102/102 [00:03<00:00, 32.19it/s, loss=0.1178, mse=0.1109, cos=0.0690]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 213: Loss=0.1361, MSE=0.1283, CosLoss=0.0774, LR=0.000020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 214/300: 100%|| 102/102 [00:03<00:00, 32.34it/s, loss=0.1539, mse=0.1451, cos=0.0880]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 214: Loss=0.1427, MSE=0.1345, CosLoss=0.0821, LR=0.000020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 215/300: 100%|| 102/102 [00:03<00:00, 32.17it/s, loss=0.1030, mse=0.0970, cos=0.0600]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 215: Loss=0.1444, MSE=0.1362, CosLoss=0.0823, LR=0.000020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 216/300: 100%|| 102/102 [00:03<00:00, 32.03it/s, loss=0.1736, mse=0.1628, cos=0.1080]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 216: Loss=0.1453, MSE=0.1369, CosLoss=0.0842, LR=0.000019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 217/300: 100%|| 102/102 [00:03<00:00, 32.12it/s, loss=0.1280, mse=0.1211, cos=0.0689]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 217: Loss=0.1379, MSE=0.1301, CosLoss=0.0784, LR=0.000019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 218/300: 100%|| 102/102 [00:03<00:00, 32.23it/s, loss=0.1454, mse=0.1371, cos=0.0829]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 218: Loss=0.1436, MSE=0.1354, CosLoss=0.0822, LR=0.000018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 219/300: 100%|| 102/102 [00:03<00:00, 32.16it/s, loss=0.1154, mse=0.1093, cos=0.0611]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 219: Loss=0.1459, MSE=0.1375, CosLoss=0.0837, LR=0.000018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 220/300: 100%|| 102/102 [00:03<00:00, 32.12it/s, loss=0.1191, mse=0.1126, cos=0.0644]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 220: Loss=0.1441, MSE=0.1358, CosLoss=0.0834, LR=0.000017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 221/300: 100%|| 102/102 [00:03<00:00, 32.16it/s, loss=0.1705, mse=0.1606, cos=0.0988]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 221: Loss=0.1421, MSE=0.1340, CosLoss=0.0811, LR=0.000017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 222/300: 100%|| 102/102 [00:03<00:00, 32.19it/s, loss=0.0852, mse=0.0803, cos=0.0488]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 222: Loss=0.1411, MSE=0.1330, CosLoss=0.0812, LR=0.000017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 223/300: 100%|| 102/102 [00:03<00:00, 32.22it/s, loss=0.1545, mse=0.1458, cos=0.0877]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 223: Loss=0.1363, MSE=0.1285, CosLoss=0.0782, LR=0.000016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 224/300: 100%|| 102/102 [00:03<00:00, 32.06it/s, loss=0.1147, mse=0.1087, cos=0.0600]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 224: Loss=0.1357, MSE=0.1280, CosLoss=0.0776, LR=0.000016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 225/300: 100%|| 102/102 [00:03<00:00, 32.15it/s, loss=0.1563, mse=0.1470, cos=0.0929]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225: Loss=0.1372, MSE=0.1294, CosLoss=0.0783, LR=0.000016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 226/300: 100%|| 102/102 [00:03<00:00, 32.14it/s, loss=0.1115, mse=0.1055, cos=0.0602]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 226: Loss=0.1419, MSE=0.1338, CosLoss=0.0811, LR=0.000015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 227/300: 100%|| 102/102 [00:03<00:00, 32.38it/s, loss=0.1138, mse=0.1078, cos=0.0603]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 227: Loss=0.1440, MSE=0.1357, CosLoss=0.0821, LR=0.000015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 228/300: 100%|| 102/102 [00:03<00:00, 32.54it/s, loss=0.1526, mse=0.1440, cos=0.0854]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 228: Loss=0.1405, MSE=0.1324, CosLoss=0.0805, LR=0.000014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 229/300: 100%|| 102/102 [00:03<00:00, 31.82it/s, loss=0.1182, mse=0.1118, cos=0.0647]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229: Loss=0.1448, MSE=0.1365, CosLoss=0.0830, LR=0.000014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 230/300: 100%|| 102/102 [00:03<00:00, 32.04it/s, loss=0.1324, mse=0.1249, cos=0.0744]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 230: Loss=0.1369, MSE=0.1291, CosLoss=0.0781, LR=0.000014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 231/300: 100%|| 102/102 [00:03<00:00, 31.99it/s, loss=0.1345, mse=0.1271, cos=0.0735]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 231: Loss=0.1472, MSE=0.1387, CosLoss=0.0846, LR=0.000013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 232/300: 100%|| 102/102 [00:03<00:00, 32.19it/s, loss=0.1042, mse=0.0982, cos=0.0595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 232: Loss=0.1390, MSE=0.1311, CosLoss=0.0791, LR=0.000013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 233/300: 100%|| 102/102 [00:03<00:00, 32.10it/s, loss=0.1354, mse=0.1276, cos=0.0777]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 233: Loss=0.1405, MSE=0.1324, CosLoss=0.0807, LR=0.000013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 234/300: 100%|| 102/102 [00:03<00:00, 32.18it/s, loss=0.1890, mse=0.1772, cos=0.1180]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 234: Loss=0.1389, MSE=0.1310, CosLoss=0.0791, LR=0.000012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 235/300: 100%|| 102/102 [00:03<00:00, 32.22it/s, loss=0.1075, mse=0.1018, cos=0.0566]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 235: Loss=0.1332, MSE=0.1257, CosLoss=0.0755, LR=0.000012\n",
      "  New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 236/300: 100%|| 102/102 [00:03<00:00, 32.60it/s, loss=0.2512, mse=0.2356, cos=0.1554]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 236: Loss=0.1416, MSE=0.1335, CosLoss=0.0815, LR=0.000012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 237/300: 100%|| 102/102 [00:03<00:00, 32.33it/s, loss=0.1729, mse=0.1630, cos=0.0988]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 237: Loss=0.1405, MSE=0.1324, CosLoss=0.0805, LR=0.000011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 238/300: 100%|| 102/102 [00:03<00:00, 32.17it/s, loss=0.1103, mse=0.1045, cos=0.0577]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 238: Loss=0.1445, MSE=0.1362, CosLoss=0.0830, LR=0.000011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 239/300: 100%|| 102/102 [00:03<00:00, 32.04it/s, loss=0.1108, mse=0.1052, cos=0.0569]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 239: Loss=0.1417, MSE=0.1335, CosLoss=0.0816, LR=0.000011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 240/300: 100%|| 102/102 [00:03<00:00, 32.17it/s, loss=0.1394, mse=0.1312, cos=0.0818]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 240: Loss=0.1509, MSE=0.1421, CosLoss=0.0882, LR=0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 241/300: 100%|| 102/102 [00:03<00:00, 32.03it/s, loss=0.1508, mse=0.1415, cos=0.0923]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241: Loss=0.1444, MSE=0.1361, CosLoss=0.0833, LR=0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 242/300: 100%|| 102/102 [00:03<00:00, 31.90it/s, loss=0.0975, mse=0.0923, cos=0.0515]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 242: Loss=0.1434, MSE=0.1352, CosLoss=0.0821, LR=0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 243/300: 100%|| 102/102 [00:03<00:00, 31.94it/s, loss=0.1373, mse=0.1290, cos=0.0832]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 243: Loss=0.1440, MSE=0.1357, CosLoss=0.0835, LR=0.000009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 244/300: 100%|| 102/102 [00:03<00:00, 32.10it/s, loss=0.1426, mse=0.1346, cos=0.0804]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 244: Loss=0.1405, MSE=0.1324, CosLoss=0.0802, LR=0.000009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 245/300: 100%|| 102/102 [00:03<00:00, 32.25it/s, loss=0.1349, mse=0.1269, cos=0.0793]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 245: Loss=0.1406, MSE=0.1325, CosLoss=0.0807, LR=0.000009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 246/300: 100%|| 102/102 [00:03<00:00, 32.57it/s, loss=0.1102, mse=0.1042, cos=0.0594]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 246: Loss=0.1376, MSE=0.1298, CosLoss=0.0783, LR=0.000008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 247/300: 100%|| 102/102 [00:03<00:00, 32.05it/s, loss=0.1228, mse=0.1159, cos=0.0687]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 247: Loss=0.1420, MSE=0.1339, CosLoss=0.0814, LR=0.000008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 248/300: 100%|| 102/102 [00:03<00:00, 32.33it/s, loss=0.1473, mse=0.1384, cos=0.0884]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 248: Loss=0.1363, MSE=0.1286, CosLoss=0.0773, LR=0.000008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 249/300: 100%|| 102/102 [00:03<00:00, 32.09it/s, loss=0.1274, mse=0.1204, cos=0.0694]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: Loss=0.1380, MSE=0.1301, CosLoss=0.0789, LR=0.000007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 250/300: 100%|| 102/102 [00:03<00:00, 32.18it/s, loss=0.1235, mse=0.1167, cos=0.0675]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 250: Loss=0.1387, MSE=0.1308, CosLoss=0.0792, LR=0.000007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 251/300: 100%|| 102/102 [00:03<00:00, 32.01it/s, loss=0.1225, mse=0.1159, cos=0.0656]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 251: Loss=0.1380, MSE=0.1301, CosLoss=0.0790, LR=0.000007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 252/300: 100%|| 102/102 [00:03<00:00, 32.26it/s, loss=0.1534, mse=0.1446, cos=0.0883]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 252: Loss=0.1414, MSE=0.1333, CosLoss=0.0816, LR=0.000007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 253/300: 100%|| 102/102 [00:03<00:00, 32.33it/s, loss=0.1113, mse=0.1054, cos=0.0587]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 253: Loss=0.1368, MSE=0.1290, CosLoss=0.0781, LR=0.000006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 254/300: 100%|| 102/102 [00:03<00:00, 32.32it/s, loss=0.0946, mse=0.0896, cos=0.0502]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 254: Loss=0.1429, MSE=0.1347, CosLoss=0.0825, LR=0.000006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 255/300: 100%|| 102/102 [00:03<00:00, 32.19it/s, loss=0.1746, mse=0.1648, cos=0.0981]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 255: Loss=0.1417, MSE=0.1336, CosLoss=0.0816, LR=0.000006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 256/300: 100%|| 102/102 [00:03<00:00, 32.25it/s, loss=0.1063, mse=0.1003, cos=0.0607]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 256: Loss=0.1394, MSE=0.1315, CosLoss=0.0794, LR=0.000006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 257/300: 100%|| 102/102 [00:03<00:00, 32.24it/s, loss=0.1148, mse=0.1087, cos=0.0611]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 257: Loss=0.1416, MSE=0.1335, CosLoss=0.0816, LR=0.000005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 258/300: 100%|| 102/102 [00:03<00:00, 32.18it/s, loss=0.0876, mse=0.0832, cos=0.0442]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 258: Loss=0.1359, MSE=0.1281, CosLoss=0.0775, LR=0.000005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 259/300: 100%|| 102/102 [00:03<00:00, 32.18it/s, loss=0.1634, mse=0.1543, cos=0.0910]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 259: Loss=0.1372, MSE=0.1294, CosLoss=0.0782, LR=0.000005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 260/300: 100%|| 102/102 [00:03<00:00, 32.22it/s, loss=0.1510, mse=0.1417, cos=0.0929]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 260: Loss=0.1415, MSE=0.1334, CosLoss=0.0817, LR=0.000005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 261/300: 100%|| 102/102 [00:03<00:00, 32.23it/s, loss=0.2017, mse=0.1895, cos=0.1223]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 261: Loss=0.1395, MSE=0.1315, CosLoss=0.0801, LR=0.000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 262/300: 100%|| 102/102 [00:03<00:00, 32.15it/s, loss=0.1264, mse=0.1193, cos=0.0716]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 262: Loss=0.1397, MSE=0.1316, CosLoss=0.0807, LR=0.000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 263/300: 100%|| 102/102 [00:03<00:00, 32.12it/s, loss=0.0808, mse=0.0767, cos=0.0409]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 263: Loss=0.1398, MSE=0.1317, CosLoss=0.0805, LR=0.000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 264/300: 100%|| 102/102 [00:03<00:00, 32.05it/s, loss=0.1542, mse=0.1455, cos=0.0876]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 264: Loss=0.1397, MSE=0.1317, CosLoss=0.0800, LR=0.000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 265/300: 100%|| 102/102 [00:03<00:00, 32.38it/s, loss=0.1414, mse=0.1326, cos=0.0871]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 265: Loss=0.1386, MSE=0.1307, CosLoss=0.0794, LR=0.000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 266/300: 100%|| 102/102 [00:03<00:00, 32.05it/s, loss=0.1028, mse=0.0975, cos=0.0535]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 266: Loss=0.1427, MSE=0.1345, CosLoss=0.0825, LR=0.000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 267/300: 100%|| 102/102 [00:03<00:00, 32.09it/s, loss=0.2371, mse=0.2219, cos=0.1519]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 267: Loss=0.1403, MSE=0.1322, CosLoss=0.0808, LR=0.000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 268/300: 100%|| 102/102 [00:03<00:00, 31.94it/s, loss=0.1184, mse=0.1112, cos=0.0720]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 268: Loss=0.1389, MSE=0.1309, CosLoss=0.0799, LR=0.000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 269/300: 100%|| 102/102 [00:03<00:00, 32.12it/s, loss=0.1511, mse=0.1426, cos=0.0844]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 269: Loss=0.1437, MSE=0.1354, CosLoss=0.0829, LR=0.000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 270/300: 100%|| 102/102 [00:03<00:00, 32.15it/s, loss=0.1694, mse=0.1591, cos=0.1034]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 270: Loss=0.1391, MSE=0.1311, CosLoss=0.0800, LR=0.000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 271/300: 100%|| 102/102 [00:03<00:00, 32.34it/s, loss=0.1413, mse=0.1331, cos=0.0818]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 271: Loss=0.1445, MSE=0.1362, CosLoss=0.0836, LR=0.000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 272/300: 100%|| 102/102 [00:03<00:00, 32.10it/s, loss=0.1122, mse=0.1062, cos=0.0598]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 272: Loss=0.1421, MSE=0.1339, CosLoss=0.0817, LR=0.000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 273/300: 100%|| 102/102 [00:03<00:00, 32.20it/s, loss=0.1752, mse=0.1649, cos=0.1030]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 273: Loss=0.1349, MSE=0.1272, CosLoss=0.0773, LR=0.000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 274/300: 100%|| 102/102 [00:03<00:00, 32.20it/s, loss=0.1571, mse=0.1477, cos=0.0933]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 274: Loss=0.1322, MSE=0.1247, CosLoss=0.0750, LR=0.000002\n",
      "  New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 275/300: 100%|| 102/102 [00:03<00:00, 32.58it/s, loss=0.1180, mse=0.1119, cos=0.0616]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 275: Loss=0.1387, MSE=0.1308, CosLoss=0.0793, LR=0.000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 276/300: 100%|| 102/102 [00:03<00:00, 32.16it/s, loss=0.1129, mse=0.1070, cos=0.0590]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 276: Loss=0.1416, MSE=0.1335, CosLoss=0.0814, LR=0.000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 277/300: 100%|| 102/102 [00:03<00:00, 32.19it/s, loss=0.1473, mse=0.1381, cos=0.0913]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 277: Loss=0.1412, MSE=0.1330, CosLoss=0.0820, LR=0.000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 278/300: 100%|| 102/102 [00:03<00:00, 32.12it/s, loss=0.0964, mse=0.0914, cos=0.0500]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 278: Loss=0.1388, MSE=0.1309, CosLoss=0.0795, LR=0.000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 279/300: 100%|| 102/102 [00:03<00:00, 32.09it/s, loss=0.0952, mse=0.0903, cos=0.0496]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 279: Loss=0.1337, MSE=0.1262, CosLoss=0.0757, LR=0.000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 280/300: 100%|| 102/102 [00:03<00:00, 32.11it/s, loss=0.1392, mse=0.1312, cos=0.0802]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 280: Loss=0.1407, MSE=0.1326, CosLoss=0.0809, LR=0.000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 281/300: 100%|| 102/102 [00:03<00:00, 32.20it/s, loss=0.1476, mse=0.1390, cos=0.0852]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 281: Loss=0.1381, MSE=0.1302, CosLoss=0.0788, LR=0.000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 282/300: 100%|| 102/102 [00:03<00:00, 32.16it/s, loss=0.1252, mse=0.1183, cos=0.0698]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 282: Loss=0.1415, MSE=0.1333, CosLoss=0.0819, LR=0.000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 283/300: 100%|| 102/102 [00:03<00:00, 32.06it/s, loss=0.1168, mse=0.1105, cos=0.0628]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 283: Loss=0.1356, MSE=0.1279, CosLoss=0.0773, LR=0.000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 284/300: 100%|| 102/102 [00:03<00:00, 32.11it/s, loss=0.1891, mse=0.1778, cos=0.1131]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 284: Loss=0.1429, MSE=0.1346, CosLoss=0.0823, LR=0.000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 285/300: 100%|| 102/102 [00:03<00:00, 32.20it/s, loss=0.1304, mse=0.1234, cos=0.0697]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 285: Loss=0.1338, MSE=0.1262, CosLoss=0.0761, LR=0.000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 286/300: 100%|| 102/102 [00:03<00:00, 32.16it/s, loss=0.1427, mse=0.1343, cos=0.0836]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286: Loss=0.1368, MSE=0.1290, CosLoss=0.0781, LR=0.000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 287/300: 100%|| 102/102 [00:03<00:00, 32.17it/s, loss=0.1417, mse=0.1330, cos=0.0870]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 287: Loss=0.1368, MSE=0.1290, CosLoss=0.0779, LR=0.000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 288/300: 100%|| 102/102 [00:03<00:00, 32.24it/s, loss=0.0876, mse=0.0831, cos=0.0446]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 288: Loss=0.1317, MSE=0.1242, CosLoss=0.0748, LR=0.000000\n",
      "  New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 289/300: 100%|| 102/102 [00:03<00:00, 31.92it/s, loss=0.1347, mse=0.1266, cos=0.0811]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 289: Loss=0.1358, MSE=0.1280, CosLoss=0.0781, LR=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 290/300: 100%|| 102/102 [00:03<00:00, 32.06it/s, loss=0.0740, mse=0.0702, cos=0.0376]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 290: Loss=0.1399, MSE=0.1319, CosLoss=0.0800, LR=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 291/300: 100%|| 102/102 [00:03<00:00, 32.10it/s, loss=0.1664, mse=0.1569, cos=0.0953]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 291: Loss=0.1358, MSE=0.1280, CosLoss=0.0777, LR=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 292/300: 100%|| 102/102 [00:03<00:00, 32.19it/s, loss=0.1588, mse=0.1493, cos=0.0941]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 292: Loss=0.1410, MSE=0.1329, CosLoss=0.0808, LR=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 293/300: 100%|| 102/102 [00:03<00:00, 32.17it/s, loss=0.1318, mse=0.1239, cos=0.0794]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 293: Loss=0.1294, MSE=0.1220, CosLoss=0.0736, LR=0.000000\n",
      "  New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 294/300: 100%|| 102/102 [00:03<00:00, 32.30it/s, loss=0.1167, mse=0.1105, cos=0.0618]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 294: Loss=0.1369, MSE=0.1291, CosLoss=0.0785, LR=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 295/300: 100%|| 102/102 [00:03<00:00, 32.66it/s, loss=0.1284, mse=0.1213, cos=0.0707]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 295: Loss=0.1360, MSE=0.1282, CosLoss=0.0775, LR=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 296/300: 100%|| 102/102 [00:03<00:00, 32.26it/s, loss=0.1864, mse=0.1750, cos=0.1142]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 296: Loss=0.1432, MSE=0.1349, CosLoss=0.0826, LR=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 297/300: 100%|| 102/102 [00:03<00:00, 32.13it/s, loss=0.0643, mse=0.0611, cos=0.0319]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 297: Loss=0.1404, MSE=0.1323, CosLoss=0.0816, LR=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 298/300: 100%|| 102/102 [00:03<00:00, 32.20it/s, loss=0.1561, mse=0.1468, cos=0.0923]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 298: Loss=0.1356, MSE=0.1279, CosLoss=0.0771, LR=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 299/300: 100%|| 102/102 [00:03<00:00, 32.30it/s, loss=0.1148, mse=0.1077, cos=0.0702]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299: Loss=0.1368, MSE=0.1290, CosLoss=0.0783, LR=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 300/300: 100%|| 102/102 [00:03<00:00, 32.12it/s, loss=0.2120, mse=0.1995, cos=0.1244]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300: Loss=0.1437, MSE=0.1354, CosLoss=0.0829, LR=0.000000\n",
      "\n",
      "============================================================\n",
      "TRAINING COMPLETE! Best loss: 0.1294\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lrate)\n",
    "# Training diffusion model\n",
    "train_diffusion_model(model=model, dataloader=dataloader, optimizer=optimizer, timesteps=timesteps, a_t=a_t, b_t=b_t, ab_t=ab_t, n_epoch=n_epoch, device=device, save_dir=save_dir, context_mask_prob=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388c2969-8663-44e6-b690-c1bbecc10ec3",
   "metadata": {},
   "source": [
    "* Now let's write decoder class for decoding embeddings back to tokens (Using professor's code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b6701554-0971-4b27-8057-c548c2fd069f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LatentToTextDecoder:\n",
    "    \"\"\"Converts denoised BERT latent vectors back to text tokens\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name='bert-base-uncased', device='cuda'):\n",
    "        self.device = device\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.bert = AutoModel.from_pretrained(model_name).to(device)\n",
    "        self.bert.eval()\n",
    "        \n",
    "        # Get BERT's token embedding matrix\n",
    "        self.token_embeddings = self.bert.embeddings.word_embeddings.weight.data\n",
    "        self.vocab_size, self.hidden_dim = self.token_embeddings.shape\n",
    "        \n",
    "        print(f\"Decoder initialized: vocab_size={self.vocab_size}, hidden_dim={self.hidden_dim}\")\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def decode_nearest_neighbor(self, denoised_latents, skip_special_tokens=True):\n",
    "        \"\"\"\n",
    "        Decode using nearest neighbor search\n",
    "        \n",
    "        Args:\n",
    "            denoised_latents: [batch, seq_len, hidden_dim]\n",
    "            skip_special_tokens: Skip [CLS], [SEP], [PAD] in output\n",
    "            \n",
    "        Returns:\n",
    "            List of decoded text strings\n",
    "        \"\"\"\n",
    "        denoised_latents = denoised_latents.to(self.device)\n",
    "        \n",
    "        # Normalize for cosine similarity\n",
    "        denoised_norm = F.normalize(denoised_latents, dim=-1)\n",
    "        token_emb_norm = F.normalize(self.token_embeddings, dim=-1)\n",
    "        \n",
    "        # Compute similarities\n",
    "        similarities = torch.matmul(denoised_norm, token_emb_norm.T)\n",
    "        \n",
    "        # Get nearest token IDs\n",
    "        token_ids = similarities.argmax(dim=-1)\n",
    "        \n",
    "        # Decode to text\n",
    "        texts = []\n",
    "        for i in range(token_ids.shape[0]):\n",
    "            tokens = token_ids[i].cpu().tolist()\n",
    "            text = self.tokenizer.decode(tokens, skip_special_tokens=skip_special_tokens)\n",
    "            texts.append(text)\n",
    "        \n",
    "        return texts\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def decode_topk_sampling(self, denoised_latents, k=5, temperature=1.0):\n",
    "        \"\"\"\n",
    "        Decode with top-k sampling for diversity\n",
    "        \"\"\"\n",
    "        denoised_latents = denoised_latents.to(self.device)\n",
    "        batch_size, seq_len, _ = denoised_latents.shape\n",
    "        \n",
    "        denoised_norm = F.normalize(denoised_latents, dim=-1)\n",
    "        token_emb_norm = F.normalize(self.token_embeddings, dim=-1)\n",
    "        \n",
    "        similarities = torch.matmul(denoised_norm, token_emb_norm.T)\n",
    "        logits = similarities / temperature\n",
    "        \n",
    "        topk_logits, topk_indices = torch.topk(logits, k, dim=-1)\n",
    "        topk_probs = F.softmax(topk_logits, dim=-1)\n",
    "        \n",
    "        token_ids = []\n",
    "        for i in range(batch_size):\n",
    "            batch_tokens = []\n",
    "            for j in range(seq_len):\n",
    "                idx = torch.multinomial(topk_probs[i, j], 1)\n",
    "                token_id = topk_indices[i, j, idx]\n",
    "                batch_tokens.append(token_id.item())\n",
    "            token_ids.append(batch_tokens)\n",
    "        \n",
    "        texts = []\n",
    "        for tokens in token_ids:\n",
    "            text = self.tokenizer.decode(tokens, skip_special_tokens=True)\n",
    "            texts.append(text)\n",
    "        \n",
    "        return texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7c26ad-75c4-4b5f-bb18-e9abd8cd1589",
   "metadata": {},
   "source": [
    "* Now let's write a function to get POS embedding while generating output using our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "96714bed-45ce-4a23-bb98-44ae0fe3850c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_pos_embedding_for_generation(words, tokenizer, bert_model, n_pos_words, device):\n",
    "    \"\"\"Function to get CONTEXTUALIZED POS embeddings for generation\"\"\"\n",
    "    words = list(words)\n",
    "    # Pad if needed\n",
    "    while len(words) < n_pos_words:\n",
    "        words.append(tokenizer.pad_token if tokenizer.pad_token else '[PAD]')\n",
    "    words = words[:n_pos_words]\n",
    "    # Join and run BERT on POS words only\n",
    "    pos_text = ' '.join(words)\n",
    "    encoded = tokenizer(pos_text, return_tensors='pt', padding='max_length', truncation=True, max_length=n_pos_words + 2).to(device)\n",
    "    outputs = bert_model(**encoded)\n",
    "    # Skipping [CLS], take n_pos_words embeddings\n",
    "    pos_emb = outputs.last_hidden_state.squeeze(0)[1:n_pos_words + 1, :]\n",
    "    return pos_emb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e94691-38a4-46d0-8cce-834ae61d4587",
   "metadata": {},
   "source": [
    "* Now let's write a sampling function which also denormalizes embedding back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "76bf4027-2f6f-4b90-a426-b0559c247a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def sample_ddpm(model, n_sample, seq_len, pos_embedding, timesteps, a_t, b_t, ab_t, device, emb_mean, emb_std):\n",
    "    \"\"\"Function to perform sampling using ddpm and also denormalize embeddings back after denoising\"\"\"\n",
    "    model.eval()\n",
    "    # Starting from pure noise\n",
    "    samples = torch.randn(n_sample, seq_len, model.hidden_dim).to(device)\n",
    "    print(f\"  Initial noise: mean={samples.mean():.4f}, std={samples.std():.4f}\")\n",
    "    for i in range(timesteps, 0, -1):\n",
    "        if i % 100 == 0:\n",
    "            print(f\"  Step {i:3d}/{timesteps}, \"\n",
    "                  f\"mean={samples.mean():.4f}, std={samples.std():.4f}\")    \n",
    "        t_normalized = torch.tensor([i / timesteps] * n_sample, device=device)\n",
    "        z = torch.randn_like(samples) if i > 1 else 0\n",
    "        pred_noise = model(samples, t_normalized, pos_embedding)\n",
    "        samples = denoise_add_noise(samples, i, pred_noise, a_t, b_t, ab_t, z)\n",
    "    print(f\"  Final (normalized): mean={samples.mean():.4f}, std={samples.std():.4f}\")\n",
    "    # Denormalizing back to BERT scale\n",
    "    samples = samples * emb_std + emb_mean\n",
    "    print(f\"  After denormalization: mean={samples.mean():.4f}, std={samples.std():.4f}\")\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fd765b-7080-46d5-9db8-7045e32079bb",
   "metadata": {},
   "source": [
    "* For decoding embedding back to text we are going to train custom decoder\n",
    "* So let's write a custom decoder class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a825860f-850f-447b-b919-a229aef2c696",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextualEmbeddingDecoder(nn.Module):\n",
    "    \"\"\"Neural network that learns to map BERT contextual embeddings back to token IDs.\"\"\"\n",
    "    def __init__(self, hidden_dim=768, vocab_size=30522, intermediate_dim=1024, n_layers=3, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.vocab_size = vocab_size\n",
    "        # Input normalization\n",
    "        self.input_norm = nn.LayerNorm(hidden_dim)\n",
    "        # Build transformation layers\n",
    "        layers = []\n",
    "        # First layer: hidden_dim -> intermediate_dim\n",
    "        layers.append(nn.Linear(hidden_dim, intermediate_dim))\n",
    "        layers.append(nn.LayerNorm(intermediate_dim))\n",
    "        layers.append(nn.GELU())\n",
    "        layers.append(nn.Dropout(dropout))\n",
    "        # Middle layers: intermediate_dim -> intermediate_dim\n",
    "        for _ in range(n_layers - 2):\n",
    "            layers.append(nn.Linear(intermediate_dim, intermediate_dim))\n",
    "            layers.append(nn.LayerNorm(intermediate_dim))\n",
    "            layers.append(nn.GELU())\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "        # Final hidden layer: intermediate_dim -> hidden_dim\n",
    "        layers.append(nn.Linear(intermediate_dim, hidden_dim))\n",
    "        layers.append(nn.LayerNorm(hidden_dim))\n",
    "        layers.append(nn.GELU())\n",
    "        self.transform = nn.Sequential(*layers)\n",
    "        # Outputing projection to vocabulary\n",
    "        self.output_proj = nn.Linear(hidden_dim, vocab_size)\n",
    "        # Residual connection weight\n",
    "        self.residual_weight = nn.Parameter(torch.tensor(0.1))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Normalizing input\n",
    "        x_norm = self.input_norm(x)\n",
    "        # Transform\n",
    "        transformed = self.transform(x_norm)\n",
    "        # Residual connection\n",
    "        combined = transformed + self.residual_weight * x_norm\n",
    "        # Projecting to vocabulary\n",
    "        logits = self.output_proj(combined)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c66998b-1c97-44e4-b486-98697f7f7361",
   "metadata": {},
   "source": [
    "* Now that we have a decoder network which maps back contextualized bert embedding back to token Id let's also write a class for training it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "955e4e82-6e82-42ba-91d2-05072ccb3728",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderTrainer:\n",
    "    \"\"\"Handles training of the ContextualEmbeddingDecoder.\"\"\"\n",
    "    def __init__(self, model_name='bert-base-uncased', device='cuda'):\n",
    "        self.device = device\n",
    "        self.model_name = model_name\n",
    "        # Loading BERT\n",
    "        print(f\"Loading BERT model: {model_name}\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.bert = AutoModel.from_pretrained(model_name).to(device)\n",
    "        self.bert.eval()\n",
    "        # Freezing BERT\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.hidden_dim = self.bert.config.hidden_size\n",
    "        self.vocab_size = self.bert.config.vocab_size\n",
    "        print(f\"Hidden dim: {self.hidden_dim}, Vocab size: {self.vocab_size}\")\n",
    "    \n",
    "    def prepare_training_data(self, texts, max_length=256):\n",
    "        \"\"\"Function to prepare training data: get BERT embeddings and corresponding token IDs.\"\"\"\n",
    "        print(f\"Preparing training data for {len(texts)} texts.\")\n",
    "        all_embeddings = []\n",
    "        all_token_ids = []\n",
    "        all_attention_masks = []\n",
    "        self.bert.eval()\n",
    "        with torch.no_grad():\n",
    "            for text in tqdm(texts):\n",
    "                # Tokenize\n",
    "                encoded = self.tokenizer(text, return_tensors='pt', padding='max_length', truncation=True, max_length=max_length).to(self.device)\n",
    "                # Geting BERT embeddings\n",
    "                outputs = self.bert(**encoded)\n",
    "                embeddings = outputs.last_hidden_state.squeeze(0).cpu()\n",
    "                # Store\n",
    "                all_embeddings.append(embeddings)\n",
    "                all_token_ids.append(encoded['input_ids'].squeeze(0).cpu())\n",
    "                all_attention_masks.append(encoded['attention_mask'].squeeze(0).cpu())\n",
    "        print(f\"  Done! Prepared {len(all_embeddings)} samples.\")\n",
    "        return all_embeddings, all_token_ids, all_attention_masks\n",
    "    \n",
    "    def train(self, texts, decoder=None, n_epochs=20, batch_size=32, lr=1e-4, noise_schedule='progressive', max_noise=0.5, max_length=256, save_path=None):\n",
    "        \"\"\"Function to train the decoder network.\"\"\"\n",
    "        # Preparing data\n",
    "        all_embeddings, all_token_ids, all_attention_masks = self.prepare_training_data(texts, max_length)\n",
    "        # Creating decoder if not provided\n",
    "        if decoder is None:\n",
    "            decoder = ContextualEmbeddingDecoder(hidden_dim=self.hidden_dim, vocab_size=self.vocab_size, intermediate_dim=1024, n_layers=3, dropout=0.1).to(self.device)\n",
    "        # Countimg parameters\n",
    "        n_params = sum(p.numel() for p in decoder.parameters() if p.requires_grad)\n",
    "        print(f\"\\nDecoder parameters: {n_params:,}\")\n",
    "        # Optimizer and loss\n",
    "        optimizer = torch.optim.AdamW(decoder.parameters(), lr=lr, weight_decay=0.01)\n",
    "        criterion = nn.CrossEntropyLoss(ignore_index=self.tokenizer.pad_token_id)\n",
    "        # Learning rate scheduler\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=n_epochs)\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"TRAINING DECODER\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"Epochs: {n_epochs}\")\n",
    "        print(f\"Batch size: {batch_size}\")\n",
    "        print(f\"Learning rate: {lr}\")\n",
    "        print(f\"Noise schedule: {noise_schedule}\")\n",
    "        print(f\"Max noise: {max_noise}\")\n",
    "        # Training loop\n",
    "        n_samples = len(all_embeddings)\n",
    "        for epoch in range(n_epochs):\n",
    "            decoder.train()\n",
    "            # Determine noise level for this epoch\n",
    "            if noise_schedule == 'progressive':\n",
    "                # Starting with low noise then gradually increase noise\n",
    "                epoch_noise = max_noise * (epoch + 1) / n_epochs\n",
    "            else:\n",
    "                epoch_noise = max_noise\n",
    "            # Shuffling data\n",
    "            indices = torch.randperm(n_samples)\n",
    "            total_loss = 0\n",
    "            total_correct = 0\n",
    "            total_tokens = 0\n",
    "            n_batches = 0\n",
    "            for batch_start in range(0, n_samples, batch_size):\n",
    "                batch_indices = indices[batch_start:batch_start + batch_size] \n",
    "                # Gathering batch data\n",
    "                batch_embeddings = torch.stack([all_embeddings[i] for i in batch_indices]).to(self.device)\n",
    "                batch_token_ids = torch.stack([all_token_ids[i] for i in batch_indices]).to(self.device)\n",
    "                batch_attention_mask = torch.stack([all_attention_masks[i] for i in batch_indices]).to(self.device)\n",
    "                # Adding noise\n",
    "                noise_level = torch.rand(1).item() * epoch_noise\n",
    "                noise = torch.randn_like(batch_embeddings) * noise_level\n",
    "                noisy_embeddings = batch_embeddings + noise\n",
    "                # Forward pass\n",
    "                logits = decoder(noisy_embeddings)\n",
    "                # Computing loss\n",
    "                loss = criterion(logits.view(-1, self.vocab_size), batch_token_ids.view(-1))\n",
    "                # Backward pass\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(decoder.parameters(), 1.0)\n",
    "                optimizer.step()\n",
    "                # Tracking metrics\n",
    "                total_loss += loss.item()\n",
    "                # Accuracy (on non-padded tokens)\n",
    "                predictions = logits.argmax(dim=-1)\n",
    "                mask = batch_attention_mask.bool()\n",
    "                correct = ((predictions == batch_token_ids) & mask).sum().item()\n",
    "                total_correct += correct\n",
    "                total_tokens += mask.sum().item()\n",
    "                n_batches += 1\n",
    "            # Updating learning rate\n",
    "            scheduler.step()\n",
    "            # Epoch statistics\n",
    "            avg_loss = total_loss / n_batches\n",
    "            accuracy = total_correct / total_tokens * 100\n",
    "            print(f\"Epoch {epoch + 1:3d}/{n_epochs} | \"\n",
    "                  f\"Loss: {avg_loss:.4f} | \"\n",
    "                  f\"Acc: {accuracy:.2f}% | \"\n",
    "                  f\"Noise: {epoch_noise:.3f} | \"\n",
    "                  f\"LR: {scheduler.get_last_lr()[0]:.6f}\")\n",
    "        # Save decoder\n",
    "        if save_path:\n",
    "            torch.save({\n",
    "                'model_state_dict': decoder.state_dict(),\n",
    "                'config': {\n",
    "                    'hidden_dim': self.hidden_dim,\n",
    "                    'vocab_size': self.vocab_size,\n",
    "                    'model_name': self.model_name\n",
    "                }\n",
    "            }, save_path)\n",
    "            print(f\"\\nDecoder saved to: {save_path}\")\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"DECODER TRAINING COMPLETE\")\n",
    "        print(f\"{'='*60}\")\n",
    "        return decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f635a55a-2f95-421b-8443-422c4afd381f",
   "metadata": {},
   "source": [
    "* Now let's train our decoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e854f468-c820-48d9-ad1d-923b3af29f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT model: bert-base-uncased\n",
      "Hidden dim: 768, Vocab size: 30522\n",
      "Preparing training data for 3274 texts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3274/3274 [00:12<00:00, 255.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Done! Prepared 3274 samples.\n",
      "\n",
      "Decoder parameters: 26,102,843\n",
      "\n",
      "============================================================\n",
      "TRAINING DECODER\n",
      "============================================================\n",
      "Epochs: 20\n",
      "Batch size: 32\n",
      "Learning rate: 0.0001\n",
      "Noise schedule: progressive\n",
      "Max noise: 0.5\n",
      "Epoch   1/20 | Loss: 6.0264 | Acc: 35.42% | Noise: 0.025 | LR: 0.000099\n",
      "Epoch   2/20 | Loss: 2.9795 | Acc: 61.56% | Noise: 0.050 | LR: 0.000098\n",
      "Epoch   3/20 | Loss: 2.0968 | Acc: 72.14% | Noise: 0.075 | LR: 0.000095\n",
      "Epoch   4/20 | Loss: 1.5827 | Acc: 79.32% | Noise: 0.100 | LR: 0.000090\n",
      "Epoch   5/20 | Loss: 1.2131 | Acc: 84.84% | Noise: 0.125 | LR: 0.000085\n",
      "Epoch   6/20 | Loss: 0.9526 | Acc: 89.43% | Noise: 0.150 | LR: 0.000079\n",
      "Epoch   7/20 | Loss: 0.7542 | Acc: 93.24% | Noise: 0.175 | LR: 0.000073\n",
      "Epoch   8/20 | Loss: 0.6034 | Acc: 95.71% | Noise: 0.200 | LR: 0.000065\n",
      "Epoch   9/20 | Loss: 0.4949 | Acc: 97.31% | Noise: 0.225 | LR: 0.000058\n",
      "Epoch  10/20 | Loss: 0.4132 | Acc: 98.24% | Noise: 0.250 | LR: 0.000050\n",
      "Epoch  11/20 | Loss: 0.3654 | Acc: 98.78% | Noise: 0.275 | LR: 0.000042\n",
      "Epoch  12/20 | Loss: 0.3200 | Acc: 99.05% | Noise: 0.300 | LR: 0.000035\n",
      "Epoch  13/20 | Loss: 0.3004 | Acc: 99.20% | Noise: 0.325 | LR: 0.000027\n",
      "Epoch  14/20 | Loss: 0.2878 | Acc: 99.29% | Noise: 0.350 | LR: 0.000021\n",
      "Epoch  15/20 | Loss: 0.2814 | Acc: 99.41% | Noise: 0.375 | LR: 0.000015\n",
      "Epoch  16/20 | Loss: 0.3148 | Acc: 99.15% | Noise: 0.400 | LR: 0.000010\n",
      "Epoch  17/20 | Loss: 0.3229 | Acc: 99.10% | Noise: 0.425 | LR: 0.000005\n",
      "Epoch  18/20 | Loss: 0.3273 | Acc: 98.96% | Noise: 0.450 | LR: 0.000002\n",
      "Epoch  19/20 | Loss: 0.3233 | Acc: 99.07% | Noise: 0.475 | LR: 0.000001\n",
      "Epoch  20/20 | Loss: 0.3482 | Acc: 98.83% | Noise: 0.500 | LR: 0.000000\n",
      "\n",
      "Decoder saved to: ./weights/decoder.pth\n",
      "\n",
      "============================================================\n",
      "DECODER TRAINING COMPLETE\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Preparing texts for decoder training\n",
    "decoder_texts = [sample['text'] for sample in all_data_samples]\n",
    "trainer = DecoderTrainer(model_name=model_name, device=device)\n",
    "decoder = trainer.train(texts=decoder_texts, n_epochs=20, batch_size=32, lr=1e-4, noise_schedule='progressive', max_noise=0.5, max_length=max_length, save_path=os.path.join(save_dir, 'decoder.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84343958-bc15-46ef-8630-71d11c61cfc0",
   "metadata": {},
   "source": [
    "* Now let's write a text generator class to generate text using model above and decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "81b3de59-c35c-4c8e-91d4-d333f2708856",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGenerator:\n",
    "    \"\"\"Class which contains functions to generate text using diffusion model and decoder\"\"\"\n",
    "    def __init__(self, diffusion_model, decoder, tokenizer, bert_model, emb_mean, emb_std, device='cuda'):\n",
    "        self.diffusion_model = diffusion_model\n",
    "        self.decoder = decoder\n",
    "        self.tokenizer = tokenizer\n",
    "        self.bert = bert_model\n",
    "        self.emb_mean = emb_mean\n",
    "        self.emb_std = emb_std\n",
    "        self.device = device\n",
    "        self.diffusion_model.eval()\n",
    "        self.decoder.eval()\n",
    "        self.bert.eval()\n",
    "        print(f\"Generator initialized with normalization: \"\n",
    "              f\"mean={emb_mean:.4f}, std={emb_std:.4f}\")\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def generate(self, pos_word_lists, seq_len=64, timesteps=1000, a_t=None, b_t=None, ab_t=None, n_pos_words=3, temperature=0.8, top_k=50, top_p=0.9):\n",
    "        \"\"\"Function to generate text\"\"\"\n",
    "        n_samples = len(pos_word_lists)\n",
    "        print(f\"\\nGenerating {n_samples} samples...\")\n",
    "        # Geting POS embeddings\n",
    "        print(\"Encoding POS words...\")\n",
    "        pos_embeddings = []\n",
    "        for words in pos_word_lists:\n",
    "            pos_emb = get_pos_embedding_for_generation(words, self.tokenizer, self.bert, n_pos_words, self.device)\n",
    "            # Normalizing POS embeddings to match training\n",
    "            pos_emb = (pos_emb - self.emb_mean) / self.emb_std\n",
    "            pos_embeddings.append(pos_emb)\n",
    "        pos_embedding = torch.stack(pos_embeddings).to(self.device)\n",
    "        print(f\"  POS embedding shape: {pos_embedding.shape}\")\n",
    "        print(f\"  POS embedding stats (normalized): \"\n",
    "              f\"mean={pos_embedding.mean():.4f}, std={pos_embedding.std():.4f}\")\n",
    "        # Running diffusion with fixed sampling\n",
    "        print(f\"Running diffusion ({timesteps} steps)...\")\n",
    "        samples = sample_ddpm(model=self.diffusion_model, n_sample=n_samples, seq_len=seq_len, pos_embedding=pos_embedding, timesteps=timesteps, a_t=a_t, b_t=b_t, ab_t=ab_t, device=self.device, emb_mean=self.emb_mean, emb_std=self.emb_std)   \n",
    "        # Decoding\n",
    "        print(\"Decoding to text...\")\n",
    "        logits = self.decoder(samples)\n",
    "        # Applying temperature and top-k/top-p sampling\n",
    "        logits = logits / temperature\n",
    "        if top_k > 0:\n",
    "            topk_vals, _ = torch.topk(logits, min(top_k, logits.size(-1)), dim=-1)\n",
    "            threshold = topk_vals[..., -1, None]\n",
    "            logits = torch.where(logits < threshold, torch.full_like(logits, float('-inf')), logits)\n",
    "        if top_p < 1.0:\n",
    "            sorted_logits, sorted_indices = torch.sort(logits, descending=True, dim=-1)\n",
    "            cumsum = torch.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n",
    "            mask = cumsum > top_p\n",
    "            mask[..., 1:] = mask[..., :-1].clone()\n",
    "            mask[..., 0] = False\n",
    "            indices_to_remove = mask.scatter(-1, sorted_indices, mask)\n",
    "            logits = logits.masked_fill(indices_to_remove, float('-inf'))\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        token_ids = torch.multinomial(probs.view(-1, probs.size(-1)), 1).view(n_samples, seq_len)\n",
    "        # Converting to text\n",
    "        texts = []\n",
    "        for i in range(n_samples):\n",
    "            text = self.tokenizer.decode(token_ids[i].cpu().tolist(), skip_special_tokens=True)\n",
    "            texts.append(text)\n",
    "        return texts, samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86dc1a6-8e94-4dd9-b430-5fa07fc80514",
   "metadata": {},
   "source": [
    "* Now let's test this Text geneartaor class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "92ea824a-2ab2-48ee-bf4d-ebc755a647c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator initialized with normalization: mean=-0.0089, std=0.4152\n",
      "\n",
      "Generating 3 samples...\n",
      "Encoding POS words...\n",
      "  POS embedding shape: torch.Size([3, 3, 768])\n",
      "  POS embedding stats (normalized): mean=-0.0057, std=1.2395\n",
      "Running diffusion (1000 steps)...\n",
      "  Initial noise: mean=-0.0043, std=0.9970\n",
      "  Step 1000/1000, mean=-0.0043, std=0.9970\n",
      "  Step 900/1000, mean=-0.0010, std=1.5945\n",
      "  Step 800/1000, mean=0.0319, std=7.0510\n",
      "  Step 700/1000, mean=0.1310, std=19.9197\n",
      "  Step 600/1000, mean=0.3090, std=42.9433\n",
      "  Step 500/1000, mean=0.5947, std=78.7806\n",
      "  Step 400/1000, mean=0.9812, std=127.5995\n",
      "  Step 300/1000, mean=1.4358, std=185.0478\n",
      "  Step 200/1000, mean=1.8839, std=241.7176\n",
      "  Step 100/1000, mean=2.2279, std=285.1319\n",
      "  Final (normalized): mean=2.3726, std=303.7939\n",
      "  After denormalization: mean=0.9761, std=126.1201\n",
      "Decoding to text...\n",
      "\n",
      "Sample 1\n",
      "POS: ['Shall', 'I', 'compare']\n",
      "Generated: your speak, let it checkzing my be much aug where shade longer who, almost ; pencil to dark show might, wanting heavy free, tend argument like proud pitchd power and pride make, by our know was beauty, approve free, knows it,. myself look that their form,?\n",
      "----------------------------------------\n",
      "\n",
      "Sample 2\n",
      "POS: ['When', 'I', 'do']\n",
      "Generated: shadow which excellence part do brave hide s thoughtsst profound might tellties a to please abundanceved,., reign, muse comfort, muse frame, it,, own., up her use ; were, the your o ve again do might be of my,less full shadow now '\n",
      "----------------------------------------\n",
      "\n",
      "Sample 3\n",
      "POS: ['Love', 'is', 'not']\n",
      "Generated: , made, beauty hideled an what stealing so which dart sensual that so remembered beauty my painting receives, an my lies as beauty beauty black? thee might might your light art, form blame ' lie which bear, to beauty, i defect car i should, beautyew hide i own a i my\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Reload BERT for generation\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "bert_model = AutoModel.from_pretrained(model_name).to(device)\n",
    "bert_model.eval()\n",
    "\n",
    "generator = TextGenerator(diffusion_model=model, decoder=decoder, tokenizer=tokenizer, bert_model=bert_model, device=device, emb_mean=dataset.get_normalization_stats()[0], emb_std=dataset.get_normalization_stats()[1])\n",
    "\n",
    "test_pos = [\n",
    "    [\"Shall\", \"I\", \"compare\"],\n",
    "    [\"When\", \"I\", \"do\"],\n",
    "    [\"Love\", \"is\", \"not\"],\n",
    "]\n",
    "\n",
    "texts, embeddings = generator.generate(pos_word_lists=test_pos, seq_len=max_length, timesteps=timesteps, a_t=a_t, b_t=b_t, ab_t=ab_t, n_pos_words=n_pos_words, temperature=0.8, top_k=50, top_p=0.9)\n",
    "\n",
    "for i, (pos, text) in enumerate(zip(test_pos, texts)):\n",
    "    print(f\"\\nSample {i + 1}\")\n",
    "    print(f\"POS: {pos}\")\n",
    "    print(f\"Generated: {text[:500]}\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c74f43e-e70b-4359-a854-58887da44d86",
   "metadata": {},
   "source": [
    "* Let's also write a function that will generate poem from saved model and decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "25558e4c-5aff-42c6-a662-f3df17b15869",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_from_saved_models(diffusion_path, decoder_path, pos_word_lists):\n",
    "    \"\"\"Function to generate using saved models with normalization.\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"GENERATING FROM SAVED MODELS\")\n",
    "    print(\"=\" * 60)\n",
    "    # Loading normalization stats\n",
    "    norm_stats_path = os.path.join(save_dir, 'norm_stats.pth')\n",
    "    if os.path.exists(norm_stats_path):\n",
    "        norm_stats = torch.load(norm_stats_path)\n",
    "        emb_mean = norm_stats['emb_mean']\n",
    "        emb_std = norm_stats['emb_std']\n",
    "    else:\n",
    "        # Trying to get from checkpoint\n",
    "        checkpoint = torch.load(diffusion_path, map_location=device)\n",
    "        emb_mean = checkpoint.get('emb_mean', 0.0)\n",
    "        emb_std = checkpoint.get('emb_std', 0.4)\n",
    "    print(f\"Normalization stats: mean={emb_mean:.4f}, std={emb_std:.4f}\")\n",
    "    # Load models\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    bert_model = AutoModel.from_pretrained(model_name).to(device)\n",
    "    bert_model.eval()\n",
    "    diffusion_model = TextDiffusionUNet(hidden_dim=hidden_dim, time_emb_dim=time_emb_dim, channels=[768, 512, 256, 128], dilations=[1, 2, 4, 8], num_heads=8, dropout=0.1).to(device)\n",
    "    checkpoint = torch.load(diffusion_path, map_location=device)\n",
    "    diffusion_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print(f\"Loaded diffusion model from epoch {checkpoint['epoch']}\")\n",
    "    decoder_checkpoint = torch.load(decoder_path, map_location=device)\n",
    "    decoder = ContextualEmbeddingDecoder(hidden_dim=decoder_checkpoint['config']['hidden_dim'], vocab_size=decoder_checkpoint['config']['vocab_size'], intermediate_dim=1024, n_layers=3, dropout=0.1).to(device)\n",
    "    decoder.load_state_dict(decoder_checkpoint['model_state_dict'])\n",
    "    # Creating generator\n",
    "    generator = TextGenerator(diffusion_model=diffusion_model, decoder=decoder, tokenizer=tokenizer, bert_model=bert_model, emb_mean=emb_mean, emb_std=emb_std, device=device)\n",
    "    \n",
    "    # Generate\n",
    "    texts, embeddings = generator.generate(pos_word_lists=pos_word_lists, seq_len=max_length, timesteps=timesteps, a_t=a_t, b_t=b_t, ab_t=ab_t, n_pos_words=n_pos_words, temperature=0.8, top_k=50, top_p=0.9)\n",
    "    \n",
    "    # Printing results\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"GENERATED TEXTS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for i, (pos, text) in enumerate(zip(pos_word_lists, texts)):\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Sample {i + 1}: {pos}\")\n",
    "        print(f\"{'='*50}\")\n",
    "        print(text)\n",
    "    \n",
    "    return texts, embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d6e682-0901-4a75-8112-23c0c6796a4f",
   "metadata": {},
   "source": [
    "* Now let's also test this function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7cc01e6a-7f9d-493b-91d8-85ffd460f45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_word_lists = [\n",
    "        [\"Shall\", \"I\", \"compare\"],\n",
    "        [\"When\", \"I\", \"do\"],\n",
    "        [\"Love\", \"is\", \"not\"],\n",
    "        [\"My\", \"love\", \"is\"],\n",
    "        [\"From\", \"fairest\", \"creatures\"],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b6a8298e-d4de-4bb5-8957-4654173d6a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "GENERATING FROM SAVED MODELS\n",
      "============================================================\n",
      "Normalization stats: mean=0.0000, std=1.0000\n",
      "Loaded diffusion model from epoch 293\n",
      "Generator initialized with normalization: mean=0.0000, std=1.0000\n",
      "\n",
      "Generating 5 samples...\n",
      "Encoding POS words...\n",
      "  POS embedding shape: torch.Size([5, 3, 768])\n",
      "  POS embedding stats (normalized): mean=-0.0117, std=0.5249\n",
      "Running diffusion (1000 steps)...\n",
      "  Initial noise: mean=-0.0013, std=0.9978\n",
      "  Step 1000/1000, mean=-0.0013, std=0.9978\n",
      "  Step 900/1000, mean=0.0027, std=1.5957\n",
      "  Step 800/1000, mean=0.0389, std=7.0248\n",
      "  Step 700/1000, mean=0.1382, std=19.6239\n",
      "  Step 600/1000, mean=0.3261, std=42.1497\n",
      "  Step 500/1000, mean=0.6143, std=77.2012\n",
      "  Step 400/1000, mean=1.0098, std=124.9193\n",
      "  Step 300/1000, mean=1.4756, std=181.0275\n",
      "  Step 200/1000, mean=1.9342, std=236.3064\n",
      "  Step 100/1000, mean=2.2839, std=278.5316\n",
      "  Final (normalized): mean=2.4275, std=296.4676\n",
      "  After denormalization: mean=2.4275, std=296.4676\n",
      "Decoding to text...\n",
      "\n",
      "============================================================\n",
      "GENERATED TEXTS\n",
      "============================================================\n",
      "\n",
      "==================================================\n",
      "Sample 1: ['Shall', 'I', 'compare']\n",
      "==================================================\n",
      "approve set, show my deeds whom., tender myed look stand beed pitch shows all my how friends i, i these till be ve.mo to under i wr, it neglect beauty my ; and of, breath, might at not can witness the yourself make to, stand must,, thinking approve\n",
      "\n",
      "==================================================\n",
      "Sample 2: ['When', 'I', 'do']\n",
      "==================================================\n",
      "' feel, rotten theirrl it make the, as, - witness, shape my rest,, i,, know, ve strength my., bear bud by myself i an strength, ised beautyfor frown absence, when muse under art,sco elements, his,. cast strength merit bad is beauty\n",
      "\n",
      "==================================================\n",
      "Sample 3: ['Love', 'is', 'not']\n",
      "==================================================\n",
      "knows beauty o, to wherein,more long, not never shade well wherein ;, praises we shows, and, call, when merit possessed of, breath some take beauty my beauty that do dare those my keep woo i power is part i blind.,. eternally o, my own, as sweets\n",
      "\n",
      "==================================================\n",
      "Sample 4: ['My', 'love', 'is']\n",
      "==================================================\n",
      ", my leaves nothing ', remembered nothing to there sha. to beauty bed hope is,ding sweets everyse make noed thing form the, thin my is cast heavy, myself ' my shows, i blind desire my shape she do that, place admit compound are an,, an i is my long\n",
      "\n",
      "==================================================\n",
      "Sample 5: ['From', 'fairest', 'creatures']\n",
      "==================================================\n",
      "want that art part, form they by hide never nothing, be beauty beauty, without under to art beauty thin approve mye i cost i, bear and. these, which captain ', my am force,? bear hide nothing might and away disperse form fear stand confined and beauty, my stay, some leaves\n"
     ]
    }
   ],
   "source": [
    "texts, embeddings = generate_from_saved_models(\n",
    "    diffusion_path=os.path.join(save_dir, f'text_diffusion_best.pth'),\n",
    "    decoder_path=os.path.join(save_dir, 'decoder.pth'),\n",
    "    pos_word_lists=pos_word_lists\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d1c64d-9151-4665-b67c-48857fd85967",
   "metadata": {},
   "source": [
    "* Now let's write a function to generate poem using model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ca67e075-e0aa-4332-9ddd-ef8c2941d5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_poem_diffusion(diffusion_path, decoder_path, seed_text, num_samples=1, \n",
    "                            seq_len=20, temperature=0.8, top_k=50, top_p=0.9):\n",
    "    \"\"\"Function to generate poem using diffusion model\"\"\"\n",
    "    # Load normalization stats\n",
    "    norm_stats_path = os.path.join(save_dir, 'norm_stats.pth')\n",
    "    if os.path.exists(norm_stats_path):\n",
    "        norm_stats = torch.load(norm_stats_path)\n",
    "        emb_mean = norm_stats['emb_mean']\n",
    "        emb_std = norm_stats['emb_std']\n",
    "    else:\n",
    "        checkpoint = torch.load(diffusion_path, map_location=device)\n",
    "        emb_mean = checkpoint.get('emb_mean', 0.0)\n",
    "        emb_std = checkpoint.get('emb_std', 0.4)\n",
    "    \n",
    "    # Load models\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    bert_model = AutoModel.from_pretrained(model_name).to(device)\n",
    "    bert_model.eval()\n",
    "    \n",
    "    # Load diffusion model\n",
    "    diffusion_model = TextDiffusionUNet(\n",
    "        hidden_dim=hidden_dim, \n",
    "        time_emb_dim=time_emb_dim, \n",
    "        channels=[768, 512, 256, 128], \n",
    "        dilations=[1, 2, 4, 8], \n",
    "        num_heads=8, \n",
    "        dropout=0.1\n",
    "    ).to(device)\n",
    "    \n",
    "    checkpoint = torch.load(diffusion_path, map_location=device)\n",
    "    diffusion_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    diffusion_model.eval()\n",
    "    \n",
    "    # Load decoder\n",
    "    decoder_checkpoint = torch.load(decoder_path, map_location=device)\n",
    "    decoder = ContextualEmbeddingDecoder(\n",
    "        hidden_dim=decoder_checkpoint['config']['hidden_dim'],\n",
    "        vocab_size=decoder_checkpoint['config']['vocab_size'],\n",
    "        intermediate_dim=1024,\n",
    "        n_layers=3,\n",
    "        dropout=0.1\n",
    "    ).to(device)\n",
    "    decoder.load_state_dict(decoder_checkpoint['model_state_dict'])\n",
    "    decoder.eval()\n",
    "    \n",
    "    # Create generator\n",
    "    generator = TextGenerator(\n",
    "        diffusion_model=diffusion_model,\n",
    "        decoder=decoder,\n",
    "        tokenizer=tokenizer,\n",
    "        bert_model=bert_model,\n",
    "        emb_mean=emb_mean,\n",
    "        emb_std=emb_std,\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    # Convert seed text to word list\n",
    "    seed_words = seed_text.strip().split()\n",
    "    \n",
    "    # Create pos_word_lists for multiple samples\n",
    "    pos_word_lists = [seed_words for _ in range(num_samples)]\n",
    "    \n",
    "    # Generate\n",
    "    texts, embeddings = generator.generate(\n",
    "        pos_word_lists=pos_word_lists,\n",
    "        seq_len=seq_len,\n",
    "        timesteps=timesteps,\n",
    "        a_t=a_t,\n",
    "        b_t=b_t,\n",
    "        ab_t=ab_t,\n",
    "        n_pos_words=len(seed_words),\n",
    "        temperature=temperature,\n",
    "        top_k=top_k,\n",
    "        top_p=top_p\n",
    "    )\n",
    "    \n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "47b855b0-d47f-4869-8fc5-99a6cf5e9a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_poem(text, words_per_line=8):\n",
    "    \"\"\"Function to format text into poem lines.\"\"\"\n",
    "    # Clean up the text\n",
    "    words = text.replace(',', ' ,').replace('.', ' .').split()\n",
    "    words = [w for w in words if w.strip()]\n",
    "    \n",
    "    lines = []\n",
    "    for i in range(0, len(words), words_per_line):\n",
    "        line = ' '.join(words[i:i + words_per_line])\n",
    "        # Clean up spacing around punctuation\n",
    "        line = line.replace(' ,', ',').replace(' .', '.')\n",
    "        lines.append(line)\n",
    "    \n",
    "    return '\\n'.join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dbb3f3fb-3d0f-4bae-bac5-365a17110e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator initialized with normalization: mean=0.0000, std=1.0000\n",
      "\n",
      "Generating 1 samples...\n",
      "Encoding POS words...\n",
      "  POS embedding shape: torch.Size([1, 4, 768])\n",
      "  POS embedding stats (normalized): mean=-0.0126, std=0.5501\n",
      "Running diffusion (1000 steps)...\n",
      "  Initial noise: mean=-0.0018, std=1.0007\n",
      "  Step 1000/1000, mean=-0.0018, std=1.0007\n",
      "  Step 900/1000, mean=0.0017, std=1.3833\n",
      "  Step 800/1000, mean=0.0260, std=5.9822\n",
      "  Step 700/1000, mean=0.0987, std=17.2368\n",
      "  Step 600/1000, mean=0.2398, std=37.3679\n",
      "  Step 500/1000, mean=0.4702, std=68.7003\n",
      "  Step 400/1000, mean=0.7848, std=111.3670\n",
      "  Step 300/1000, mean=1.1591, std=161.5587\n",
      "  Step 200/1000, mean=1.5312, std=211.0282\n",
      "  Step 100/1000, mean=1.8126, std=248.8259\n",
      "  Final (normalized): mean=1.9257, std=264.8960\n",
      "  After denormalization: mean=1.9257, std=264.8960\n",
      "Decoding to text...\n",
      "\n",
      "--- Generated Poem ---\n",
      "beauty. that fashion to no to '\n",
      "measure are, every, of as things\n",
      "nothing merit, tomb the my an,\n",
      "poets,sw my have full beauty be receives\n",
      ", and render i all dark blushing approve\n",
      "they bonds muse. beautyzed pitch grew stay\n",
      ", bark, much my which knows part\n",
      "is my,. lie approve, my\n",
      "art the favor merit, lookst standbed,\n",
      "be one shame to like ; my,\n",
      "part excuse should their taken stars keep are\n",
      "my i beauty\n"
     ]
    }
   ],
   "source": [
    "# Test diffusion poem generation\n",
    "poems = generate_poem_diffusion(\n",
    "    diffusion_path=os.path.join(save_dir, f'text_diffusion_best.pth'),\n",
    "    decoder_path=os.path.join(save_dir, 'decoder.pth'),\n",
    "    seed_text=\"shall i compare thee\",\n",
    "    seq_len=100\n",
    ")\n",
    "\n",
    "for i, poem in enumerate(poems):\n",
    "    print(f\"\\n--- Generated Poem ---\")\n",
    "    print(format_poem(poem))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
